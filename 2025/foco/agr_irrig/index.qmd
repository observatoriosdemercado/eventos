---
title: "REVISÃO DE FOCO DA UNIDADE - AGRICULTURA IRRIGADA"
author: "João Ricardo F. de Lima"
date: "today"
editor: source
lang: pt
language: 
  toc-title-document: '<a href="https://www.embrapa.br/semiarido" target="_blank"><img src="https://github.com/observatoriosdemercado/manga/blob/main/logo_embrapa.jpg?raw=true" alt="Logotipo Embrapa" width="150"></a>'
format: 
  html:
    toc: true
    toc_float:
      collapsed: yes
      smooth_scroll: yes
    toc-location: left
    code-fold: false
    embed-resources: true
    page-layout: full
#    fig-asp: 0.618
    fig-width: 10
    fig-height: 8
#    fig-dpi: 200
    fig-align: center
    df-print: paged
theme:
  light: flatly
execute:
  echo: false
  message: false
  warning: false
  cache: false
jupyter: python3
---

## Revisão de Foco

Esta análise é para a agricultura irrigada. 

```{python}
#| eval: true
#| echo: false
#| message: false
#| warning: false

import pandas as pd
from pandas import NA
import re
import unicodedata

# Load dataset
df = (
    pd.read_csv('dados/agr_irrig.csv', sep=';')
)

# 1) nomes atuais (vêm direto do df)
old_cols = list(df.columns)

# 2) seus novos nomes (na MESMA ordem das colunas atuais)
new_cols = [
    "data","email","nome","cidade_uf","perfil",
    "qualidade_pesq","relevancia_solucoes","agilidade_respostas","conhecimento_tecnico",
    "interacao_agro","comunicacao","oportunidades","riscos",
    "importancia_melhoramento","importancia_manejo_agua","importancia_manejo_doencas","importancia_manejo_pragas",
    "importancia_sistemas_prod","importancia_monit_gases","importancia_ferramentas_biotec","importancia_tecno_alimen",
    "importancia_poscolheita","importancia_mercado",
    "satisfacao_melhoramento","satisfacao_manejo_agua","satisfacao_manejo_doencas","satisfacao_manejo_pragas",
    "satisfacao_sistemas_prod","satisfacao_monit_gases","satisfacao_ferramentas_biotec","satisfacao_tecno_alimen",
    "satisfacao_poscolheita","satisfacao_mercado",
    "demandas","comentarios","contribuicao_sociedade"
]

# 3) checar e aplicar
if len(old_cols) != len(new_cols):
    raise ValueError(f"Número de colunas difere: {len(old_cols)} ≠ {len(new_cols)}")

mapping = dict(zip(old_cols, new_cols))
df = df.rename(columns=mapping)

# conferir
#print(df.columns.tolist())
```

```{python}
# ajuste na variável data
df["data"] = pd.to_datetime(df["data"], dayfirst=True, errors="coerce")
df[["data"]].head()

# ajuste de cidade
def strip_acc(s): 
    return "".join(ch for ch in unicodedata.normalize("NFKD", str(s)) if not unicodedata.combining(ch))

def norm_key(x):
    x = strip_acc(str(x)).upper().strip()
    x = re.sub(r"\s+", " ", x)
    return x

# mapeamento MANUAL (para sua base agr_irrig)
over = {
    # --- Petrolina e variações ---
    "PETROLINA/PE": "Petrolina-PE",
    "PETROLINA-PE": "Petrolina-PE",
    "PETROLINA PE": "Petrolina-PE",
    "PETROLINA": "Petrolina-PE",                 # se quiser forçar PE quando vier só "Petrolina"
    "PETROLINA PERNAMBUCO": "Petrolina-PE",
    "PETROLINA-PERNAMBUCO": "Petrolina-PE",
    "PETROLINA - PERNAMBUCO": "Petrolina-PE",
    "PETROLINA - PE": "Petrolina-PE",
    "PETROLINA -PE": "Petrolina-PE",
    "PETROLINA- PE": "Petrolina-PE",

    # --- Estados sozinhos ---
    "PE": "-PE",
    "PERNAMBUCO": "-PE",
    "BAHIA": "-BA",
    "CEARA": "-CE",
    "SAO PAULO": "-SP",

    # --- Juazeiro (BA) ---
    "JUAZEIRO-BA": "Juazeiro-BA",
    "JUAZEIRO/BA": "Juazeiro-BA",
    "JUAZEIRO BAHIA": "Juazeiro-BA",
    "JUAZEIRO-BAHIA": "Juazeiro-BA",
    "JUAZEIRO - BAHIA": "Juazeiro-BA",
    "JUAZEIRO BA": "Juazeiro-BA",
    "JUAZEIRO, BAHIA": "Juazeiro-BA",

    # --- Recife ---
    "RECIFE-PERNAMBUCO": "Recife-PE",
    "RECIFE - PERNAMBUCO": "Recife-PE",

    # --- Santa Maria da Boa Vista (PE) ---
    "SANTA MARIA DA BOA VISTA-PE": "Santa Maria da Boa Vista-PE",
    "SANTA MARIA D BOA VISTA": "Santa Maria da Boa Vista-PE",

    # --- Lagoa Grande (PE) ---
    "LAGOA GRANDE-PE": "Lagoa Grande-PE",
    "LAGOA GRANDE PE": "Lagoa Grande-PE",
    "LAGOA GRANDE PE ": "Lagoa Grande-PE",

    # --- Fortaleza (CE) ---
    "FORTALEZA-CE": "Fortaleza-CE",
    "FORTALEZA CEARA": "Fortaleza-CE",
    "FORTALEZA, CEARA": "Fortaleza-CE",

    # --- Russas (CE) ---
    "RUSSAS-CE": "Russas-CE",

    # --- Umarizal (RN) ---
    "UMARIZAL RN": "Umarizal-RN",

    # --- Assú (RN) ---
    "ASSU-RIO GRANDE DO NORTE": "Assú-RN",
    "ASSU - RIO GRANDE DO NORTE": "Assú-RN",

    # --- Itajú do Colônia (BA) ---
    "ITAJU DO COLONIA BAHIA": "Itajú do Colônia-BA",

    # --- Jequié (BA) ---
    "JEQUIE BA": "Jequié-BA",

    # --- Casa Nova (BA) ---
    "CASA NOVA": "Casa Nova-BA",

    # --- Santa Inês (BA) ---
    "SANTA INES-BA": "Santa Inês-BA",

    # --- Filadélfia (BA) ---
    "FILADELFIA-BA": "Filadélfia-BA",
    "FILADELFIA - BA": "Filadélfia-BA",

    # --- Itiúba (BA) ---
    "ITIUBA BAHIA": "Itiúba-BA",
    "ITIUBA-BA": "Itiúba-BA",
    "ITIUBA - BA": "Itiúba-BA",

    # --- Teresina (PI) ---
    "TERESINA-PI": "Teresina-PI",
    "TERESINA, PI": "Teresina-PI",

    # --- Brasília (DF) ---
    "BRASILIA-DF": "Brasília-DF",

    # --- Anagé (BA) ---
    "ANAGE BAHIA": "Anagé-BA",

    # --- RegiÃO Nordeste (caso especial) ---
    "REGICAO NORDESTE": "Petrolina-PE",   # sua entrada veio como "REGIÇAO NORDESTE"

    # --- Fortaleza, Ceará (com vírgula) já coberto pelo normalizador acima ---
}

# aplicar o mapeamento
df["cidade_uf2"] = df["cidade_uf"].map(lambda x: over.get(norm_key(x), pd.NA))

# conferir o que ainda ficou sem padronizar
pendentes = (
    df.loc[df["cidade_uf2"].isna(), "cidade_uf"]
      .astype(str).str.strip()
      .value_counts()
      .reset_index().rename(columns={"index":"resposta","cidade_uf":"freq"})
)
pendentes.head(50)

# criaçao das variáveis cidade e estado

def split_cidade_estado(val):
    if pd.isna(val):
        return (pd.NA, pd.NA)
    s = str(val).strip()
    s_cf = s.casefold()

    # casos especiais
    if s_cf == "exterior":
        return ("Exterior", "Exterior")
    if s_cf == "nordeste":
        return ("Nordeste", "Nordeste")

    # Cidade-UF ou -UF
    m = re.match(r"^\s*(.*?)\s*-\s*([A-Za-z]{2})\s*$", s)
    if m:
        cidade = m.group(1).strip() or pd.NA
        uf = m.group(2).upper().strip()
        return (cidade, uf)
    return (pd.NA, pd.NA)

# aplica e cria as novas colunas
df[["cidade", "uf"]] = df["cidade_uf2"].apply(lambda x: pd.Series(split_cidade_estado(x)))
```

# Estatística Descritiva do Estado

```{python}
(df["uf"].value_counts(normalize=True) * 100).round(1).astype(str) + "%"
```

```{python}
#import pandas as pd
from plotnine import *

# 1) preparar dados (percentuais por UF, ordenados)
dist = (
    df['uf'].fillna('Sem UF')                      # evita NaN aparecer na legenda
      .value_counts(dropna=False)
      .rename_axis('uf').reset_index(name='n')
)
dist['pct'] = dist['n'] / dist['n'].sum() * 100
dist = dist.sort_values('pct', ascending=False).reset_index(drop=True)

# manter ordem no eixo e na legenda
dist['uf'] = pd.Categorical(dist['uf'], categories=dist['uf'], ordered=True)
pad = max(1.0, dist['pct'].max() * 0.03)   # ~6% da barra mais alta ou 1.5, o maior
dist['label']  = dist['pct'].round(1).astype(str) + '%'
dist['y_text'] = dist['pct'] + pad
y_top = dist['y_text'].max() + pad          # garante folga no topo

plot = (
    ggplot(dist, aes(x='uf', y='pct', fill='uf'))
    + geom_col(width=0.75)
    + geom_text(aes(y='y_text', label='label'), va='bottom', size=13)
    + scale_y_continuous(
        limits=(0, y_top),                   # <<< evita cortar a 1ª etiqueta
        expand=(0, 0),
        labels=lambda v: [f'{x:.0f}%' for x in v]
    )
    + scale_x_discrete(expand=(0, 0)) 
    + labs(title='', x='', y='%', fill='UF')
    + theme(
        figure_size=(10, 8),
        legend_position='none',
        legend_direction='horizontal',
        legend_title=element_text(size=13),
        legend_text=element_text(size=13),
        axis_text_y=element_text(size=13),
        axis_text_x=element_text(size=13, angle=15, ha='right')
    )
)

plot.show()
```

```{python}
# tira espaços nas pontas (evita falhas de casca)
df["perfil"] = df["perfil"].astype(str).str.strip()

# mapeamentos desejados
mapping = {
    "Universidade/Pesquisador": "Universidade/IF/Pesquisador",
    "Professora": "Universidade/IF/Pesquisador",
    "Pesquisador aposentado": "Universidade/IF/Pesquisador",
    "Professor IF": "Universidade/IF/Pesquisador",
    "Analista da Embrapa": "Pesquisador/Analista da Embrapa",
    "Pesquisador da Embrapa": "Pesquisador/Analista da Embrapa",
    "GER. EXECUTIVO DO SINDICATO DOS PROD. RURAIS": "Outros",
    "GERENTE EXECUTIVO DO SINDICATO DOS PROD. RURAIS": "Outros",
    "BANCO DO NORDESTE DO BRASIL": "Outros",
    "Empresa Privada": "Outros", 
    "Terceiro Setor": "Outros", 
    "Sociedade civil organizada (ONGs, entidades representativas, movimentos sociais)": "Sociedade Civil Organizada",
    "Agropecuária": "Outros",# sugestão; troque aqui se preferir outro rótulo
}

df["perfil"] = df["perfil"].replace(mapping)

# normaliza espaços e bordas
#df["perfil"] = df["perfil"].astype(str).str.replace(r"\s+", " ", regex=True).str.strip()

# mapeia Empresa Privada -> Outros
#df["perfil"] = df["perfil"].replace({"Empresa Privada": "Outros"})

# conferir
#df["perfil"].value_counts()
```

# Estatística Descritiva do Perfil ou sua Organização

```{python}
(df["perfil"].value_counts(normalize=True) * 100).round(1).astype(str) + "%"
```

```{python}
#import pandas as pd
#from plotnine import *

# 1) preparar dados (percentuais por perfil, ordenados)
dist = (
    df['perfil'].fillna('Sem Perfil')                      # evita NaN aparecer na legenda
      .value_counts(dropna=False)
      .rename_axis('perfil').reset_index(name='n')
)
dist['pct'] = dist['n'] / dist['n'].sum() * 100
dist = dist.sort_values('pct', ascending=False).reset_index(drop=True)

# manter ordem no eixo e na legenda
dist['perfil'] = pd.Categorical(dist['perfil'], categories=dist['perfil'], ordered=True)
pad = max(1.0, dist['pct'].max() * 0.06)   # ~6% da barra mais alta ou 1.5, o maior
dist['label']  = dist['pct'].round(1).astype(str) + '%'
dist['y_text'] = dist['pct'] + pad
y_top = dist['y_text'].max() + pad          # garante folga no topo

plot = (
    ggplot(dist, aes(x='perfil', y='pct', fill='perfil'))
    + geom_col(width=0.75)
    + geom_text(aes(y='y_text', label='label'), va='bottom', size=13)
    + scale_y_continuous(
        limits=(0, y_top),                   # <<< evita cortar a 1ª etiqueta
        expand=(0, 0),
        labels=lambda v: [f'{x:.0f}%' for x in v]
    )
    + scale_x_discrete(expand=(0, 0)) 
    + labs(title='', x='', y='%', fill='PERFIL')
    + theme(
        figure_size=(10, 8),
        legend_position='none',
        legend_direction='horizontal',
        legend_title=element_text(size=13),
        legend_text=element_text(size=13),
        axis_text_y=element_text(size=13),
        axis_text_x=element_text(size=13, angle=45, ha='right')
    )
)

plot.show()
```

# Estatística Descritiva do Perfil X Estado (%)

```{python}
# ordem das colunas (UF). Pode ser alfabética ou pela frequência geral
uf_order = sorted(df["uf"].dropna().unique().tolist())
# ou: uf_order = df["uf"].value_counts().index.tolist()

# % por perfil (cada linha soma 100)
ct_pct = pd.crosstab(
    df["perfil"],   # linhas
    df["uf"],       # colunas
    normalize="index"
).reindex(columns=uf_order, fill_value=0).mul(100).round(1)

# (opcional) formato "x.x%"
ct_pct_fmt = ct_pct.map(lambda x: f"{x:.1f}")

ct_pct_fmt  # tabela pronta

```

# Percepção sobre o desempenho, a competência e o impacto da Embrapa Semiárido no setor agropecuário 

## Estatística sobre a qualidade da pesquisa e inovação desenvolvida pela Embrapa Semiárido

```{python}
ordem = ["Muito Ruim","Ruim","Regular","Boa","Excelente", "Não tenho opinião"]
map_q = {k:i for i,k in enumerate(ordem)}          # Muito Ruim=0 … Excelente=4
df["qualidade_pesq_code"] = df["qualidade_pesq"].map(map_q).astype("Int64")
#df[["qualidade_pesq","qualidade_pesq_code"]].head()
```

```{python}
(df["qualidade_pesq"].value_counts(normalize=True) * 100).round(1).astype(str) + "%"
```

```{python}
# 1) preparar dados (percentuais por qualidade_pesq, ordenados)
dist = (
    df['qualidade_pesq'].fillna('Sem Resposta')                      # evita NaN aparecer na legenda
      .value_counts(dropna=False)
      .rename_axis('qualidade_pesq').reset_index(name='n')
)
dist['pct'] = dist['n'] / dist['n'].sum() * 100

# ordem fixa da escala + "Sem Resposta" ao final
#cats = ["Não tenho opinião", "Muito Ruim", "Ruim", "Regular", "Boa", "Excelente"]

# reindex para aparecerem todas as categorias (mesmo as ausentes) na ordem da escala
dist = (dist.set_index('qualidade_pesq')
            .reindex(ordem, fill_value=0)
            .reset_index())
#dist = dist.sort_values('pct', ascending=False).reset_index(drop=True)

# manter ordem no eixo e na legenda
#dist['qualidade_pesq'] = pd.Categorical(dist['qualidade_pesq'], categories=dist['qualidade_pesq'], ordered=True)
# manter ordem no eixo e na legenda
dist['qualidade_pesq'] = pd.Categorical(dist['qualidade_pesq'], categories=ordem, ordered=True)
pad = max(1.0, dist['pct'].max() * 0.04)   # ~6% da barra mais alta ou 1.5, o maior
dist['label']  = dist['pct'].round(1).astype(str) + '%'
dist['y_text'] = dist['pct'] + pad
y_top = dist['y_text'].max() + pad          # garante folga no topo

plot = (
    ggplot(dist, aes(x='qualidade_pesq', y='pct', fill='qualidade_pesq'))
    + geom_col(width=0.75)
    + geom_text(aes(y='y_text', label='label'), va='bottom', size=13)
    + scale_y_continuous(
        limits=(0, y_top),                   # <<< evita cortar a 1ª etiqueta
        expand=(0, 0),
        labels=lambda v: [f'{x:.0f}%' for x in v]
    )
    + scale_x_discrete(expand=(0, 0)) 
    + labs(title='Qualidade da Pesquisa', x='', y='%', fill='QUALIDADE DA PESQUISA')
    + theme(
        figure_size=(10, 8),
        legend_position='none',
        legend_direction='horizontal',
        legend_title=element_text(size=13),
        legend_text=element_text(size=13),
        axis_text_y=element_text(size=13),
        axis_text_x=element_text(size=13, angle=45, ha='right')
    )
)

plot.show()
```

### Estatística Descritiva do Perfil x Qualidade Pesquisa (%)

```{python}
ordem = ["Não tenho opinião", "Muito Ruim","Ruim","Regular","Boa","Excelente"]
ct_pct = pd.crosstab(
    df["perfil"],
    pd.Categorical(df["qualidade_pesq"], categories=ordem, ordered=True),
    normalize="index"            # fração por linha
).reindex(columns=ordem, fill_value=0).mul(100).round(1)

ct_pct  # -> números (ex.: 42.5). Se quiser “%”:
ct_pct_fmt = ct_pct.applymap(lambda x: f"{x:.1f}")
ct_pct_fmt_desc = ct_pct_fmt.reindex(columns=ordem[::-1])
ct_pct_fmt_desc
```

### Estatística Descritiva do Estado x Qualidade Pesquisa (%)

```{python}
ordem = ["Não tenho opinião", "Muito Ruim","Ruim","Regular","Boa","Excelente"]
ct_pct = pd.crosstab(
    df["uf"],
    pd.Categorical(df["qualidade_pesq"], categories=ordem, ordered=True),
    normalize="index"            # fração por linha
).reindex(columns=ordem, fill_value=0).mul(100).round(1)

ct_pct  # -> números (ex.: 42.5). Se quiser “%”:
ct_pct_fmt = ct_pct.applymap(lambda x: f"{x:.1f}")
ct_pct_fmt_desc = ct_pct_fmt.reindex(columns=ordem[::-1])
ct_pct_fmt_desc
```

## Nível de relevância das soluções e tecnologias que a Embrapa Semiárido tem  oferecido

```{python}
ordem = ["Nenhuma Relevância","Baixa Relevância","Média Relevância","Alta Relevância","Essencial","Não tenho opinião"]
map_q = {k:i for i,k in enumerate(ordem)}          # Muito Ruim=0 … Excelente=4
df["relevancia_solucoes_code"] = df["relevancia_solucoes"].map(map_q).astype("Int64")
```

```{python}
(df["relevancia_solucoes"].value_counts(normalize=True) * 100).round(1).astype(str) + "%"
```

```{python}
# 1) preparar dados (percentuais por qualidade_pesq, ordenados)
dist = (
    df['relevancia_solucoes'].fillna('Sem Resposta')                      # evita NaN aparecer na legenda
      .value_counts(dropna=False)
      .rename_axis('relevancia_solucoes').reset_index(name='n')
)
dist['pct'] = dist['n'] / dist['n'].sum() * 100
#dist = dist.sort_values('pct', ascending=False).reset_index(drop=True)

# manter ordem no eixo e na legenda
#dist['relevancia_solucoes'] = pd.Categorical(dist['relevancia_solucoes'], categories=dist['relevancia_solucoes'], ordered=True)

# reindex para aparecerem todas as categorias (mesmo as ausentes) na ordem da escala
dist = (dist.set_index('relevancia_solucoes')
            .reindex(ordem, fill_value=0)
            .reset_index())

# manter ordem no eixo e na legenda
dist['relevancia_solucoes'] = pd.Categorical(dist['relevancia_solucoes'], categories=ordem, ordered=True)
pad = max(1.0, dist['pct'].max() * 0.04)   # ~6% da barra mais alta ou 1.5, o maior
dist['label']  = dist['pct'].round(1).astype(str) + '%'
dist['y_text'] = dist['pct'] + pad
y_top = dist['y_text'].max() + pad          # garante folga no topo

plot = (
    ggplot(dist, aes(x='relevancia_solucoes', y='pct', fill='relevancia_solucoes'))
    + geom_col(width=0.75)
    + geom_text(aes(y='y_text', label='label'), va='bottom', size=13)
    + scale_y_continuous(
        limits=(0, y_top),                   # <<< evita cortar a 1ª etiqueta
        expand=(0, 0),
        labels=lambda v: [f'{x:.0f}%' for x in v]
    )
    + scale_x_discrete(expand=(0, 0)) 
    + labs(title='Relevância das Soluções', x='', y='%', fill='RELEVÂNCIA DAS SOLUÇÕES')
    + theme(
        figure_size=(10, 8),
        legend_position='none',
        legend_direction='horizontal',
        legend_title=element_text(size=13),
        legend_text=element_text(size=13),
        axis_text_y=element_text(size=13),
        axis_text_x=element_text(size=13, angle=45, ha='right')
    )
)

plot.show()
```

## Agilidade da Embrapa Semiárido em responder às demandas e desafios

```{python}
ordem = ["Muito Lenta","Lenta","Regular","Ágil","Muito Ágil","Não tenho opinião"]
map_q = {k:i for i,k in enumerate(ordem)}          # Muito Ruim=0 … Excelente=4
df["agilidade_respostas_code"] = df["agilidade_respostas"].map(map_q).astype("Int64")
```

```{python}
(df["agilidade_respostas"].value_counts(normalize=True) * 100).round(1).astype(str) + "%"
```

```{python}
# 1) preparar dados (percentuais por qualidade_pesq, ordenados)
dist = (
    df['agilidade_respostas'].fillna('Sem Resposta')                      # evita NaN aparecer na legenda
      .value_counts(dropna=False)
      .rename_axis('agilidade_respostas').reset_index(name='n')
)
dist['pct'] = dist['n'] / dist['n'].sum() * 100
#dist = dist.sort_values('pct', ascending=False).reset_index(drop=True)

# manter ordem no eixo e na legenda
#dist['agilidade_respostas'] = pd.Categorical(dist['agilidade_respostas'], categories=dist['agilidade_respostas'], ordered=True)
# reindex para aparecerem todas as categorias (mesmo as ausentes) na ordem da escala
dist = (dist.set_index('agilidade_respostas')
            .reindex(ordem, fill_value=0)
            .reset_index())

# manter ordem no eixo e na legenda
dist['agilidade_respostas'] = pd.Categorical(dist['agilidade_respostas'], categories=ordem, ordered=True)
pad = max(1.0, dist['pct'].max() * 0.04)   # ~6% da barra mais alta ou 1.5, o maior
dist['label']  = dist['pct'].round(1).astype(str) + '%'
dist['y_text'] = dist['pct'] + pad
y_top = dist['y_text'].max() + pad          # garante folga no topo

plot = (
    ggplot(dist, aes(x='agilidade_respostas', y='pct', fill='agilidade_respostas'))
    + geom_col(width=0.75)
    + geom_text(aes(y='y_text', label='label'), va='bottom', size=13)
    + scale_y_continuous(
        limits=(0, y_top),                   # <<< evita cortar a 1ª etiqueta
        expand=(0, 0),
        labels=lambda v: [f'{x:.0f}%' for x in v]
    )
    + scale_x_discrete(expand=(0, 0)) 
    + labs(title='Agilidade das Respostas', x='', y='%', fill='AGILIDADE DAS RESPOSTAS')
    + theme(
        figure_size=(10, 8),
        legend_position='none',
        legend_direction='horizontal',
        legend_title=element_text(size=13),
        legend_text=element_text(size=13),
        axis_text_y=element_text(size=13),
        axis_text_x=element_text(size=13, angle=45, ha='right')
    )
)

plot.show()
```

## Conhecimento técnico da equipe da Embrapa Semiárido

```{python}
ordem = ["Muito Insuficiente","Insuficiente","Adequado","Forte","Excepcional","Não tenho opinião"]
map_q = {k:i for i,k in enumerate(ordem)}          # Muito Ruim=0 … Excelente=4
df["conhecimento_tecnico_code"] = df["conhecimento_tecnico"].map(map_q).astype("Int64")
```

```{python}
(df["conhecimento_tecnico"].value_counts(normalize=True) * 100).round(1).astype(str) + "%"
```

```{python}
# 1) preparar dados (percentuais por qualidade_pesq, ordenados)
dist = (
    df['conhecimento_tecnico'].fillna('Sem Resposta')                      # evita NaN aparecer na legenda
      .value_counts(dropna=False)
      .rename_axis('conhecimento_tecnico').reset_index(name='n')
)
dist['pct'] = dist['n'] / dist['n'].sum() * 100
#dist = dist.sort_values('pct', ascending=False).reset_index(drop=True)

# manter ordem no eixo e na legenda
#dist['conhecimento_tecnico'] = pd.Categorical(dist['conhecimento_tecnico'], categories=dist['conhecimento_tecnico'], ordered=True)
# reindex para aparecerem todas as categorias (mesmo as ausentes) na ordem da escala
dist = (dist.set_index('conhecimento_tecnico')
            .reindex(ordem, fill_value=0)
            .reset_index())

# manter ordem no eixo e na legenda
dist['conhecimento_tecnico'] = pd.Categorical(dist['conhecimento_tecnico'], categories=ordem, ordered=True)
pad = max(1.0, dist['pct'].max() * 0.04)   # ~6% da barra mais alta ou 1.5, o maior
dist['label']  = dist['pct'].round(1).astype(str) + '%'
dist['y_text'] = dist['pct'] + pad
y_top = dist['y_text'].max() + pad          # garante folga no topo

plot = (
    ggplot(dist, aes(x='conhecimento_tecnico', y='pct', fill='conhecimento_tecnico'))
    + geom_col(width=0.75)
    + geom_text(aes(y='y_text', label='label'), va='bottom', size=13)
    + scale_y_continuous(
        limits=(0, y_top),                   # <<< evita cortar a 1ª etiqueta
        expand=(0, 0),
        labels=lambda v: [f'{x:.0f}%' for x in v]
    )
    + scale_x_discrete(expand=(0, 0)) 
    + labs(title='Conhecimento Técnico da Equipe', x='', y='%', fill='CONHECIMENTO TÉCNICO')
    + theme(
        figure_size=(10, 8),
        legend_position='none',
        legend_direction='horizontal',
        legend_title=element_text(size=13),
        legend_text=element_text(size=13),
        axis_text_y=element_text(size=13),
        axis_text_x=element_text(size=13, angle=45, ha='right')
    )
)

plot.show()
```

## Interação da equipe técnica da Embrapa Semiárido com os membros do setor agropecuário

```{python}
ordem = ["Muito Insuficiente","Insuficiente","Adequado","Forte","Excepcional","Não tenho opinião"]
map_q = {k:i for i,k in enumerate(ordem)}          # Muito Ruim=0 … Excelente=4
df["interacao_agro_code"] = df["interacao_agro"].map(map_q).astype("Int64")
```

```{python}
(df["interacao_agro"].value_counts(normalize=True) * 100).round(1).astype(str) + "%"
```

```{python}
# 1) preparar dados (percentuais por qualidade_pesq, ordenados)
dist = (
    df['interacao_agro'].fillna('Sem Resposta')                      # evita NaN aparecer na legenda
      .value_counts(dropna=False)
      .rename_axis('interacao_agro').reset_index(name='n')
)
dist['pct'] = dist['n'] / dist['n'].sum() * 100
#dist = dist.sort_values('pct', ascending=False).reset_index(drop=True)

# manter ordem no eixo e na legenda
#dist['interacao_agro'] = pd.Categorical(dist['interacao_agro'], categories=dist['interacao_agro'], ordered=True)
# reindex para aparecerem todas as categorias (mesmo as ausentes) na ordem da escala
dist = (dist.set_index('interacao_agro')
            .reindex(ordem, fill_value=0)
            .reset_index())

# manter ordem no eixo e na legenda
dist['interacao_agro'] = pd.Categorical(dist['interacao_agro'], categories=ordem, ordered=True)
pad = max(1.0, dist['pct'].max() * 0.04)   # ~6% da barra mais alta ou 1.5, o maior
dist['label']  = dist['pct'].round(1).astype(str) + '%'
dist['y_text'] = dist['pct'] + pad
y_top = dist['y_text'].max() + pad          # garante folga no topo

plot = (
    ggplot(dist, aes(x='interacao_agro', y='pct', fill='interacao_agro'))
    + geom_col(width=0.75)
    + geom_text(aes(y='y_text', label='label'), va='bottom', size=13)
    + scale_y_continuous(
        limits=(0, y_top),                   # <<< evita cortar a 1ª etiqueta
        expand=(0, 0),
        labels=lambda v: [f'{x:.0f}%' for x in v]
    )
    + scale_x_discrete(expand=(0, 0)) 
    + labs(title='Interação da equipe técnica com o Agro', x='', y='%', fill='INTERAÇAO TÉCNICA')
    + theme(
        figure_size=(10, 8),
        legend_position='none',
        legend_direction='horizontal',
        legend_title=element_text(size=13),
        legend_text=element_text(size=13),
        axis_text_y=element_text(size=13),
        axis_text_x=element_text(size=13, angle=45, ha='right')
    )
)

plot.show()
```

## Comunicação da Embrapa Semiárido sobre suas tecnologias

```{python}
ordem = ["Muito Ineficaz","Ineficaz","Regular","Eficaz","Muito Eficaz","Não tenho opinião"]
map_q = {k:i for i,k in enumerate(ordem)}          # Muito Ruim=0 … Excelente=4
df["comunicacao_code"] = df["comunicacao"].map(map_q).astype("Int64")
```

```{python}
(df["comunicacao"].value_counts(normalize=True) * 100).round(1).astype(str) + "%"
```

```{python}
# 1) preparar dados (percentuais por qualidade_pesq, ordenados)
dist = (
    df['comunicacao'].fillna('Sem Resposta')                      # evita NaN aparecer na legenda
      .value_counts(dropna=False)
      .rename_axis('comunicacao').reset_index(name='n')
)
dist['pct'] = dist['n'] / dist['n'].sum() * 100
#dist = dist.sort_values('pct', ascending=False).reset_index(drop=True)

# manter ordem no eixo e na legenda
#dist['comunicacao'] = pd.Categorical(dist['comunicacao'], categories=dist['comunicacao'], ordered=True)
# reindex para aparecerem todas as categorias (mesmo as ausentes) na ordem da escala
dist = (dist.set_index('comunicacao')
            .reindex(ordem, fill_value=0)
            .reset_index())

# manter ordem no eixo e na legenda
dist['comunicacao'] = pd.Categorical(dist['comunicacao'], categories=ordem, ordered=True)
pad = max(1.0, dist['pct'].max() * 0.04)   # ~6% da barra mais alta ou 1.5, o maior
dist['label']  = dist['pct'].round(1).astype(str) + '%'
dist['y_text'] = dist['pct'] + pad
y_top = dist['y_text'].max() + pad          # garante folga no topo

plot = (
    ggplot(dist, aes(x='comunicacao', y='pct', fill='comunicacao'))
    + geom_col(width=0.75)
    + geom_text(aes(y='y_text', label='label'), va='bottom', size=13)
    + scale_y_continuous(
        limits=(0, y_top),                   # <<< evita cortar a 1ª etiqueta
        expand=(0, 0),
        labels=lambda v: [f'{x:.0f}%' for x in v]
    )
    + scale_x_discrete(expand=(0, 0)) 
    + labs(title='Comunicação sobre suas tecnologias', x='', y='%', fill='COMUNICAÇÃO TECNOLOGIAS')
    + theme(
        figure_size=(10, 8),
        legend_position='none',
        legend_direction='horizontal',
        legend_title=element_text(size=13),
        legend_text=element_text(size=13),
        axis_text_y=element_text(size=13),
        axis_text_x=element_text(size=13, angle=45, ha='right')
    )
)

plot.show()
```

# Oportunidades e prioridades para o desenvolvimento tecnológico e de inovação, bem como os riscos iminentes que demandam atenção imediata

## Oportunidades tecnológicas na agricultura irrigada que devem ser priorizadas

```{python}
#import re, unicodedata
#import pandas as pd

# --- as 7 opções válidas, exatamente como você quer ver nas colunas ---
valid_opts = [
    "Desenvolvimento de sensores e tecnologias para uma irrigação inteligente e eficiente",
    "Criação de Bases de dados e integração solo-planta-fertilizantes para otimização do manejo de fertilizantes",
    "Melhoramento genético e variedades adaptadas e tolerantes a estresses bióticos e abióticos",
    "Tecnologias de manejo fitossanitário de precisão, controle biológico de pragas e detecção precoce de doenças",
    "Práticas de manejo do solo e uso de microrganismos para aumentar fertilidade e reduzir pegada hídrica e de carbono",
]

def norm(s: str) -> str:
    s = "".join(ch for ch in unicodedata.normalize("NFKD", str(s)) if not unicodedata.combining(ch))
    s = s.casefold().strip()
    s = re.sub(r"\s+", " ", s)
    return s

valid_norm = {norm(v): v for v in valid_opts}

def split_opcions_with_commas(raw):
    # saída default
    out = [pd.NA, pd.NA, pd.NA, pd.NA]
    if pd.isna(raw) or not str(raw).strip():
        return pd.Series(out, index=["oportunidades_1","oportunidades_2","oportunidades_3","oportunidades_4"])

    # 1) dividir pela vírgula (forms/Excel)
    parts = [p.strip() for p in str(raw).split(",")]

    # 2) juntar blocos consecutivos até bater numa opção válida normalizada
    rec, unk = [], []
    i, n = 0, len(parts)
    while i < n:
        matched = False
        # tenta juntar de i..j, crescendo j
        for j in range(i, n):
            candidate = ", ".join(parts[i:j+1]).strip()
            if norm(candidate) in valid_norm:
                rec.append(valid_norm[norm(candidate)])
                i = j + 1
                matched = True
                break
        if not matched:
            # não formou nenhuma opção válida — este pedaço é desconhecido;
            # (tente absorver só 1 part; o próximo a gente tenta de novo)
            unk.append(parts[i])
            i += 1

    # 3) preencher colunas conforme a regra
    for k in range(min(3, len(rec))):
        out[k] = rec[k]

    if unk:
        # qualquer coisa não listada vai para a 4ª
        out[3] = " | ".join([u for u in unk if u])
    elif len(rec) > 3:
        # se não houver desconhecidas, a(s) válidas extra(s) vão para a 4ª
        out[3] = " | ".join(rec[3:])

    return pd.Series(out, index=["oportunidades_1","oportunidades_2","oportunidades_3","oportunidades_4"])

# 4) aplicar
df[["oportunidades_1","oportunidades_2","oportunidades_3","oportunidades_4"]] = (
    df["oportunidades"].apply(split_opcions_with_commas)
)

```

```{python}
#import re, unicodedata
#import pandas as pd

# --- mapeamento: rótulo completo -> nome da dummy ---
rotulo_para_dummy = {
    # 5 oficiais:
    "Desenvolvimento de sensores e tecnologias para uma irrigação inteligente e eficiente": "irriga_inteligente",
    "Criação de Bases de dados e integração solo-planta-fertilizantes para otimização do manejo de fertilizantes": "base_dados_fertiliza",
    "Melhoramento genético e variedades adaptadas e tolerantes a estresses bióticos e abióticos": "melhoramento_estresses",
    "Tecnologias de manejo fitossanitário de precisão, controle biológico de pragas e detecção precoce de doenças": "manejo_fito",
    "Práticas de manejo do solo e uso de microrganismos para aumentar fertilidade e reduzir pegada hídrica e de carbono": "manejo_solo",
    # 5 extras:
    "Variedades com todas as caraterísticas acima e ainda que atendam as exigências do mercado": "variedades",
    "Tecnologia para adpatar-se ao aquecimento do clima.": "tecnol_clima",
    "Atualizar muitos dados tem muita coisas que já tá a frente da Embrapa a muitos anos principalmente na manga tem muitas pesquisas feita na clorofila agropecuária que Embrapa nem sabe...": "atualizar_dados",
    "Desenvolvimento e adaptação de máquinas e ou implementos agrícolas que atenda as necessidades da médio e pequeno produtores": "maquinas_pequenos",
    "Agricultura Biossalina": "agr_biossalina",
}

# normalizador (tira acento/caixa e compacta espaços)
def norm(s: str) -> str:
    s = "".join(ch for ch in unicodedata.normalize("NFKD", str(s)) if not unicodedata.combining(ch))
    s = s.casefold()
    s = re.sub(r"\s+", " ", s).strip()
    return s

# versões normalizadas das chaves
normkey_to_dummy = {norm(k): v for k, v in rotulo_para_dummy.items()}

# helper: pega todas as seleções da linha (1..3 + cada item de _4)
def coletar_selecoes(row):
    itens = []
    for c in ["oportunidades_1","oportunidades_2","oportunidades_3"]:
        v = row.get(c, pd.NA)
        if pd.notna(v) and str(v).strip():
            itens.append(str(v))
    v4 = row.get("oportunidades_4", pd.NA)
    if pd.notna(v4) and str(v4).strip():
        # _4 pode ter múltiplos, separados por " | "
        for t in str(v4).split("|"):
            t = t.strip()
            if t:
                itens.append(t)
    return [norm(x) for x in itens]

# cria todas as dummies (0/1)
all_norm_cols = df.apply(coletar_selecoes, axis=1)

for nk, dummy_name in normkey_to_dummy.items():
    df[dummy_name] = all_norm_cols.apply(lambda lst: int(nk in lst))

# checagens rápidas
dummy_cols = list(normkey_to_dummy.values())
#print("Criadas:", dummy_cols)
#print("Somas (quantos marcaram cada opção):")
#print(df[dummy_cols].sum().sort_values(ascending=False))

```

```{python}
# série com as proporções
s = (df[dummy_cols].mean()*100).round(1).sort_values(ascending=False)

# vira DataFrame com 2 colunas
tabela = s.rename_axis("opcao").reset_index(name="perc")
tabela

```

```{python}
#import pandas as pd
#from plotnine import *

# ---- 0) mapeamentos ----
dummy_para_rotulo_curto = {
    "irriga_inteligente": "Irrigação inteligente",
    "base_dados_fertiliza": "Bases de dados (fert.)",
    "melhoramento_estresses": "Variedades tolerantes",
    "manejo_fito": "Manejo fitossanitário",
    "manejo_solo": "Manejo do solo (micro)",
    "variedades": "Variedades p/ mercado",
    "tecnol_clima": "Adaptação ao clima",
    "atualizar_dados": "Atualização de dados",
    "maquinas_pequenos": "Máquinas p/ pequenos",
    "agr_biossalina": "Agricultura biossalina",
}

# se você tiver o dicionário dos rótulos longos (originais), ótimo:
rotulo_original = {
    "irriga_inteligente": "Desenvolvimento de sensores e tecnologias para uma irrigação inteligente e eficiente",
    "base_dados_fertiliza": "Criação de Bases de dados e integração solo-planta-fertilizantes para otimização do manejo de fertilizantes",
    "melhoramento_estresses": "Melhoramento genético e variedades adaptadas e tolerantes a estresses bióticos e abióticos",
    "manejo_fito": "Tecnologias de manejo fitossanitário de precisão, controle biológico de pragas e detecção precoce de doenças",
    "manejo_solo": "Práticas de manejo do solo e uso de microrganismos para aumentar fertilidade e reduzir pegada hídrica e de carbono",
    "variedades": "Variedades com todas as características acima e que atendam às exigências do mercado",
    "tecnol_clima": "Tecnologia para adaptar-se ao aquecimento do clima",
    "atualizar_dados": "Atualizar bases: muitas informações dispersas/obsoletas; integrar e organizar dados",
    "maquinas_pequenos": "Desenvolver/adaptar máquinas e implementos para médios e pequenos produtores",
    "agr_biossalina": "Agricultura biossalina",
}

# ---- 1) partimos da sua 'tabela' (colunas: 'opcao', 'perc') ----
# tabela = s.rename_axis("opcao").reset_index(name="perc")  # já feito por você

# 1) Paleta fixa (10 cores) — troque pelos seus hex se já tiver um padrão

CORES_FIXAS = {
    "Irrigação inteligente": "#3B0056",
    "Bases de dados (fert.)": "#444C8A",
    "Variedades tolerantes": "#2D6F7A",
    "Manejo fitossanitário": "#2FA178",
    "Manejo do solo (micro)": "#9BD34E",
    "Variedades p/ mercado": "#F4E24A",
    "Adaptação ao clima": '#6d1575',
    "Atualização de dados": '#595f8f',
    "Máquinas p/ pequenos": '#178496',
    "Agricultura biossalina": '#076140',
}

# rótulo curto e rótulo de texto com vírgula
tabela = tabela.copy()
tabela["opcao_curta"] = tabela["opcao"].map(dummy_para_rotulo_curto).fillna(tabela["opcao"])
tabela["label_pct"]   = tabela["perc"].map(lambda v: f"{v:.1f}%".replace(".", ","))
tabela["cor"] = tabela["opcao_curta"].map(CORES_FIXAS)

# ordenar pela % (decrescente) e “travar” a ordem no eixo
tabela = tabela.sort_values("perc", ascending=True)  # ascending=True pq vamos dar coord_flip
tabela["opcao_curta"] = pd.Categorical(tabela["opcao_curta"], categories=tabela["opcao_curta"], ordered=True)

# ---- 2) gráfico (barras horizontais) ----
plot = (
    ggplot(tabela, aes(x="opcao_curta", y="perc", fill="opcao_curta"))
    + geom_col(width=0.65)
    + geom_text(aes(label="label_pct"), nudge_y=1.2, size=11, ha="left")
    + coord_flip()
    + scale_fill_manual(values=list(tabela.drop_duplicates("opcao_curta")["cor"]))
    + labs(
        title="Oportunidades tecnológicas na agricultura irrigada (priorização)",
        x="",
        y="Percentual dos respondentes (%)",
    )
    + scale_y_continuous(expand=(0.01, 0), limits=(0, tabela["perc"].max()*1.15))
    + theme(
        figure_size=(10, 8),
        panel_grid_major_y=element_blank(),
        axis_text_y=element_text(size=13),
        axis_text_x=element_text(size=13),
        plot_title=element_text(size=12, weight="bold"),
        plot_caption=element_text(size=9),
        legend_title=element_blank(),
        legend_position="none"
    )
)
plot.show()

# ---- 3) “Legenda” para o slide: curto x descrição completa ----
legenda = (
    tabela[["opcao", "opcao_curta"]]
    .assign(descricao=tabela["opcao"].map(rotulo_original))
    .rename(columns={"opcao_curta": "rótulo_curto", "descricao": "descrição"})
    .drop_duplicates()
)
# Você pode exibir 'legenda' como uma tabela no slide.
```

## Oportunidades tecnológicas na agricultura irrigada que devem ser priorizadas para o Perfil Produtores

```{python}
# guarda a base completa apenas uma vez
if "DF_ALL" not in globals():
    DF_ALL = df.copy()

# --- FILTRO OPCIONAL: manter só respondentes "Produtor Rural" ---
FILTRO_PRODUTOR = True  # mude para False para voltar à base completa

COL_RESP = "perfil"           # <<< ajuste para o nome da sua coluna
ROTULOS_PRODUTOR = ["Produtor Rural", "Produtor"]  # rótulos aceitos (ajuste se precisar)

if FILTRO_PRODUTOR:
    mask_prod = (
        df[COL_RESP]
        .astype("string")
        .str.normalize("NFKD")            # robusto a acentos
        .str.encode("ascii", "ignore").str.decode("ascii")
        .str.contains("|".join(ROTULOS_PRODUTOR), case=False, na=False)
    )
    df = DF_ALL.loc[mask_prod].copy()         # <<<<< a partir daqui, seu código segue igual
    # print(f"Filtrados {mask_prod.sum()} produtores de {len(mask_prod)} respostas.")

#import re, unicodedata
#import pandas as pd

# --- as 7 opções válidas, exatamente como você quer ver nas colunas ---
valid_opts = [
    "Desenvolvimento de sensores e tecnologias para uma irrigação inteligente e eficiente",
    "Criação de Bases de dados e integração solo-planta-fertilizantes para otimização do manejo de fertilizantes",
    "Melhoramento genético e variedades adaptadas e tolerantes a estresses bióticos e abióticos",
    "Tecnologias de manejo fitossanitário de precisão, controle biológico de pragas e detecção precoce de doenças",
    "Práticas de manejo do solo e uso de microrganismos para aumentar fertilidade e reduzir pegada hídrica e de carbono",
]

def norm(s: str) -> str:
    s = "".join(ch for ch in unicodedata.normalize("NFKD", str(s)) if not unicodedata.combining(ch))
    s = s.casefold().strip()
    s = re.sub(r"\s+", " ", s)
    return s

valid_norm = {norm(v): v for v in valid_opts}

def split_opcions_with_commas(raw):
    # saída default
    out = [pd.NA, pd.NA, pd.NA, pd.NA]
    if pd.isna(raw) or not str(raw).strip():
        return pd.Series(out, index=["oportunidades_1","oportunidades_2","oportunidades_3","oportunidades_4"])

    # 1) dividir pela vírgula (forms/Excel)
    parts = [p.strip() for p in str(raw).split(",")]

    # 2) juntar blocos consecutivos até bater numa opção válida normalizada
    rec, unk = [], []
    i, n = 0, len(parts)
    while i < n:
        matched = False
        # tenta juntar de i..j, crescendo j
        for j in range(i, n):
            candidate = ", ".join(parts[i:j+1]).strip()
            if norm(candidate) in valid_norm:
                rec.append(valid_norm[norm(candidate)])
                i = j + 1
                matched = True
                break
        if not matched:
            # não formou nenhuma opção válida — este pedaço é desconhecido;
            # (tente absorver só 1 part; o próximo a gente tenta de novo)
            unk.append(parts[i])
            i += 1

    # 3) preencher colunas conforme a regra
    for k in range(min(3, len(rec))):
        out[k] = rec[k]

    if unk:
        # qualquer coisa não listada vai para a 4ª
        out[3] = " | ".join([u for u in unk if u])
    elif len(rec) > 3:
        # se não houver desconhecidas, a(s) válidas extra(s) vão para a 4ª
        out[3] = " | ".join(rec[3:])

    return pd.Series(out, index=["oportunidades_1","oportunidades_2","oportunidades_3","oportunidades_4"])

# 4) aplicar
df[["oportunidades_1","oportunidades_2","oportunidades_3","oportunidades_4"]] = (
    df["oportunidades"].apply(split_opcions_with_commas)
)

```

```{python}
#import re, unicodedata
#import pandas as pd

# --- mapeamento: rótulo completo -> nome da dummy ---
rotulo_para_dummy = {
    # 5 oficiais:
    "Desenvolvimento de sensores e tecnologias para uma irrigação inteligente e eficiente": "irriga_inteligente",
    "Criação de Bases de dados e integração solo-planta-fertilizantes para otimização do manejo de fertilizantes": "base_dados_fertiliza",
    "Melhoramento genético e variedades adaptadas e tolerantes a estresses bióticos e abióticos": "melhoramento_estresses",
    "Tecnologias de manejo fitossanitário de precisão, controle biológico de pragas e detecção precoce de doenças": "manejo_fito",
    "Práticas de manejo do solo e uso de microrganismos para aumentar fertilidade e reduzir pegada hídrica e de carbono": "manejo_solo",
    # 5 extras:
    "Variedades com todas as caraterísticas acima e ainda que atendam as exigências do mercado": "variedades",
    "Tecnologia para adpatar-se ao aquecimento do clima.": "tecnol_clima",
    "Atualizar muitos dados tem muita coisas que já tá a frente da Embrapa a muitos anos principalmente na manga tem muitas pesquisas feita na clorofila agropecuária que Embrapa nem sabe...": "atualizar_dados",
    "Desenvolvimento e adaptação de máquinas e ou implementos agrícolas que atenda as necessidades da médio e pequeno produtores": "maquinas_pequenos",
    "Agricultura Biossalina": "agr_biossalina",
}

# normalizador (tira acento/caixa e compacta espaços)
def norm(s: str) -> str:
    s = "".join(ch for ch in unicodedata.normalize("NFKD", str(s)) if not unicodedata.combining(ch))
    s = s.casefold()
    s = re.sub(r"\s+", " ", s).strip()
    return s

# versões normalizadas das chaves
normkey_to_dummy = {norm(k): v for k, v in rotulo_para_dummy.items()}

# helper: pega todas as seleções da linha (1..3 + cada item de _4)
def coletar_selecoes(row):
    itens = []
    for c in ["oportunidades_1","oportunidades_2","oportunidades_3"]:
        v = row.get(c, pd.NA)
        if pd.notna(v) and str(v).strip():
            itens.append(str(v))
    v4 = row.get("oportunidades_4", pd.NA)
    if pd.notna(v4) and str(v4).strip():
        # _4 pode ter múltiplos, separados por " | "
        for t in str(v4).split("|"):
            t = t.strip()
            if t:
                itens.append(t)
    return [norm(x) for x in itens]

# cria todas as dummies (0/1)
all_norm_cols = df.apply(coletar_selecoes, axis=1)

for nk, dummy_name in normkey_to_dummy.items():
    df[dummy_name] = all_norm_cols.apply(lambda lst: int(nk in lst))

# checagens rápidas
dummy_cols = list(normkey_to_dummy.values())
#print("Criadas:", dummy_cols)
#print("Somas (quantos marcaram cada opção):")
#print(df[dummy_cols].sum().sort_values(ascending=False))

```

```{python}
# série com as proporções
s = (df[dummy_cols].mean()*100).round(1).sort_values(ascending=False)

# vira DataFrame com 2 colunas
tabela = s.rename_axis("opcao").reset_index(name="perc")
tabela

```

```{python}
#import pandas as pd
#from plotnine import *

# ---- 0) mapeamentos ----
dummy_para_rotulo_curto = {
    "irriga_inteligente": "Irrigação inteligente",
    "base_dados_fertiliza": "Bases de dados (fert.)",
    "melhoramento_estresses": "Variedades tolerantes",
    "manejo_fito": "Manejo fitossanitário",
    "manejo_solo": "Manejo do solo (micro)",
    "variedades": "Variedades p/ mercado",
    "tecnol_clima": "Adaptação ao clima",
    "atualizar_dados": "Atualização de dados",
    "maquinas_pequenos": "Máquinas p/ pequenos",
    "agr_biossalina": "Agricultura biossalina",
}

# se você tiver o dicionário dos rótulos longos (originais), ótimo:
rotulo_original = {
    "irriga_inteligente": "Desenvolvimento de sensores e tecnologias para uma irrigação inteligente e eficiente",
    "base_dados_fertiliza": "Criação de Bases de dados e integração solo-planta-fertilizantes para otimização do manejo de fertilizantes",
    "melhoramento_estresses": "Melhoramento genético e variedades adaptadas e tolerantes a estresses bióticos e abióticos",
    "manejo_fito": "Tecnologias de manejo fitossanitário de precisão, controle biológico de pragas e detecção precoce de doenças",
    "manejo_solo": "Práticas de manejo do solo e uso de microrganismos para aumentar fertilidade e reduzir pegada hídrica e de carbono",
    "variedades": "Variedades com todas as características acima e que atendam às exigências do mercado",
    "tecnol_clima": "Tecnologia para adaptar-se ao aquecimento do clima",
    "atualizar_dados": "Atualizar bases: muitas informações dispersas/obsoletas; integrar e organizar dados",
    "maquinas_pequenos": "Desenvolver/adaptar máquinas e implementos para médios e pequenos produtores",
    "agr_biossalina": "Agricultura biossalina",
}

# ---- 1) partimos da sua 'tabela' (colunas: 'opcao', 'perc') ----
# tabela = s.rename_axis("opcao").reset_index(name="perc")  # já feito por você

# 1) Paleta fixa (10 cores) — troque pelos seus hex se já tiver um padrão

CORES_FIXAS = {
    "Irrigação inteligente": "#3B0056",
    "Bases de dados (fert.)": "#444C8A",
    "Variedades tolerantes": "#2D6F7A",
    "Manejo fitossanitário": "#2FA178",
    "Manejo do solo (micro)": "#9BD34E",
    "Variedades p/ mercado": "#F4E24A",
    "Adaptação ao clima": '#6d1575',
    "Atualização de dados": '#595f8f',
    "Máquinas p/ pequenos": '#178496',
    "Agricultura biossalina": '#076140',
}

# rótulo curto e rótulo de texto com vírgula
tabela = tabela.copy()
tabela["opcao_curta"] = tabela["opcao"].map(dummy_para_rotulo_curto).fillna(tabela["opcao"])
tabela["label_pct"]   = tabela["perc"].map(lambda v: f"{v:.1f}%".replace(".", ","))
tabela["cor"] = tabela["opcao_curta"].map(CORES_FIXAS)

# ordenar pela % (decrescente) e “travar” a ordem no eixo
tabela = tabela.sort_values("perc", ascending=True)  # ascending=True pq vamos dar coord_flip
tabela["opcao_curta"] = pd.Categorical(tabela["opcao_curta"], categories=tabela["opcao_curta"], ordered=True)

# ---- 2) gráfico (barras horizontais) ----
plot = (
    ggplot(tabela, aes(x="opcao_curta", y="perc", fill="opcao_curta"))
    + geom_col(width=0.65)
    + geom_text(aes(label="label_pct"), nudge_y=1.2, size=11, ha="left")
    + coord_flip()
    + scale_fill_manual(values=list(tabela.drop_duplicates("opcao_curta")["cor"]))
    + labs(
        title="Oportunidades tecnológicas na agricultura irrigada (priorização)",
        x="",
        y="Percentual dos respondentes (%)",
    )
    + scale_y_continuous(expand=(0.01, 0), limits=(0, tabela["perc"].max()*1.15))
    + theme(
        figure_size=(10, 8),
        panel_grid_major_y=element_blank(),
        axis_text_y=element_text(size=13),
        axis_text_x=element_text(size=13),
        plot_title=element_text(size=12, weight="bold"),
        plot_caption=element_text(size=9),
        legend_title=element_blank(),
        legend_position="none"
    )
)
plot.show()

# ---- 3) “Legenda” para o slide: curto x descrição completa ----
legenda = (
    tabela[["opcao", "opcao_curta"]]
    .assign(descricao=tabela["opcao"].map(rotulo_original))
    .rename(columns={"opcao_curta": "rótulo_curto", "descricao": "descrição"})
    .drop_duplicates()
)
# Você pode exibir 'legenda' como uma tabela no slide.

df = DF_ALL.copy()

```

## Riscos na agricultura irrigada que merecem atenção imediata

```{python}
#import pandas as pd

valid_opts = [
    "A escassez, a variabilidade hídrica e os eventos climáticos extremos representam desafios para a produção agrícola",
    "O uso ineficiente da água, que pode proporcionar a degradação ambiental e aumentar a escassez de recursos hídricos",
    "A ausência de sensores confiáveis e de sistemas inteligentes de irrigação que  limitam a eficiência no uso da água e a competitividade do produtor",
    "A redução da disponibilidade de mão-de-obra para trabalhos em atividades operacionais de campo",
    "As perdas pós-colheita e a baixa resistência das frutas ao transporte a longas distâncias comprometem a competitividade",
    "A vulnerabilidade a pragas, doenças, estresses bióticos/abióticos e a falta de automação na colheita e avaliação de qualidade são entraves à produção",
]

def norm(s: str) -> str:
    s = "".join(ch for ch in unicodedata.normalize("NFKD", str(s)) if not unicodedata.combining(ch))
    s = s.casefold().strip()
    s = re.sub(r"\s+", " ", s)
    return s

valid_norm = {norm(v): v for v in valid_opts}

def split_riscos_with_commas(raw):
    out = [pd.NA, pd.NA, pd.NA, pd.NA]
    if pd.isna(raw) or not str(raw).strip():
        return pd.Series(out, index=["riscos_1","riscos_2","riscos_3","riscos_4"])

    # 1) normalizar separadores: transforma ; e quebras de linha em vírgula
    txt = str(raw).replace(";", ",")
    txt = re.sub(r"[\r\n]+", ",", txt)

    # 2) split por vírgula e limpeza de bullets/hífens
    parts = [re.sub(r"^[\-\•]\s*", "", p.strip()) for p in txt.split(",")]
    parts = [p for p in parts if p]  # remove vazios

    # 3) “parser por blocos” até bater exatamente numa opção válida
    rec, unk, vistos = [], [], set()
    i, n = 0, len(parts)
    while i < n:
        matched = False
        for j in range(i, n):
            candidate = ", ".join(parts[i:j+1]).strip()
            key = norm(candidate)
            if key in valid_norm:
                lab = valid_norm[key]
                if lab not in vistos:
                    rec.append(lab); vistos.add(lab)
                i = j + 1
                matched = True
                break
        if not matched:
            unk.append(parts[i])
            i += 1

    # 4) preencher 1–3 com válidas (na ordem)
    for k in range(min(3, len(rec))):
        out[k] = rec[k]

    # 5) riscos_4 = desconhecidas (se houver) SENÃO válidas extras (4ª+)
    if unk:
        out[3] = " | ".join(dict.fromkeys(unk))
    elif len(rec) > 3:
        out[3] = " | ".join(rec[3:])

    return pd.Series(out, index=["riscos_1","riscos_2","riscos_3","riscos_4"])

# aplicar
df[["riscos_1","riscos_2","riscos_3","riscos_4"]] = df["riscos"].apply(split_riscos_with_commas)

```

```{python}
#import re, unicodedata
#import pandas as pd
from collections import defaultdict

# --- mapeamento: rótulo completo -> nome da dummy (edite os nomes se preferir) ---
rotulo_para_dummy_riscos = {
    "A escassez, a variabilidade hídrica e os eventos climáticos extremos representam desafios para a produção agrícola": "risco_clima",
    "O uso ineficiente da água, que pode proporcionar a degradação ambiental e aumentar a escassez de recursos hídricos": "inefic_agua",
    "A ausência de sensores confiáveis e de sistemas inteligentes de irrigação que  limitam a eficiência no uso da água e a competitividade do produtor": "ausencia_sensores",
    "A redução da disponibilidade de mão-de-obra para trabalhos em atividades operacionais de campo": "reducao_maodeobra",
    "As perdas pós-colheita e a baixa resistência das frutas ao transporte a longas distâncias comprometem a competitividade": "resistencias_pos_colhe",
    "A vulnerabilidade a pragas, doenças, estresses bióticos/abióticos e a falta de automação na colheita e avaliação de qualidade são entraves à produção": "vulnerab_pragas",
    "Resistência de pragas e doenças aos defensivos.": "vulnerab_pragas",
}

# normalizador (tira acento/caixa e compacta espaços)
def norm(s: str) -> str:
    s = "".join(ch for ch in unicodedata.normalize("NFKD", str(s)) if not unicodedata.combining(ch))
    s = s.casefold()
    s = re.sub(r"\s+", " ", s).strip()
    return s

# versões normalizadas das chaves
normkey_to_dummy_riscos = {norm(k): v for k, v in rotulo_para_dummy_riscos.items()}

# helper: pega as seleções da linha (somente riscos_1.._3; ignoramos riscos_4 pois é NA)
def coletar_riscos(row):
    itens = []
    for c in ["riscos_1","riscos_2","riscos_3","riscos_4"]:
        v = row.get(c, pd.NA)
        if pd.notna(v) and str(v).strip():
            itens.append(str(v))
    return [norm(x) for x in itens]

# cria as 7 dummies (0/1)
all_norm = df.apply(coletar_riscos, axis=1)

# --- AGRUPA keys por dummy, para poder fazer OR (any) corretamente ---
keys_by_dummy = defaultdict(list)
for nk, dummy in normkey_to_dummy_riscos.items():
    keys_by_dummy[dummy].append(nk)

# cria as dummies (0/1) — OR entre todas as chaves daquele dummy
for dummy, keys in keys_by_dummy.items():
    df[dummy] = all_norm.apply(lambda lst: int(any(k in lst for k in keys)))

# lista final de dummies criadas
dummy_riscos = list(keys_by_dummy.keys())
#print("Criadas:", dummy_riscos)
#print("Somas (quantos marcaram cada risco):")
#print(df[dummy_riscos].sum().sort_values(ascending=False))
```

```{python}
# série com as proporções (%)
r = (df[dummy_riscos].mean() * 100).round(1).sort_values(ascending=False)

# vira DataFrame com 2 colunas (opcao, perc)
tabela = r.rename_axis("opcao").reset_index(name="perc")
tabela
```

```{python}
#import pandas as pd
#from plotnine import *

# ---- 0) mapeamentos ----
dummy_para_rotulo_curto = {
    "risco_clima": "Clima & extremos",
    "inefic_agua": "Uso ineficiente da água",
    "ausencia_sensores": "Sem sensores/irrig. inteligente",
    "reducao_maodeobra": "Menor mão de obra disponível",
    "resistencias_pos_colhe": "Perdas pós-colheita",
    "vulnerab_pragas": "Pragas/doenças & automação",
}

# 1) Paleta fixa (10 cores) — troque pelos seus hex se já tiver um padrão

CORES_FIXAS = {
    "Clima & extremos": "#9BD34E",
    "Sem sensores/irrig. inteligente": "#F4E24A",
    "Menor mão de obra disponível": '#6d1575',
    "Pragas/doenças & automação": '#595f8f',
    "Uso Ineficiente da Água": '#178496',
    "Perdas pós-colheita": '#076140',
}

# rótulo curto e rótulo de texto com vírgula
tabela = tabela.copy()
tabela["opcao_curta"] = tabela["opcao"].map(dummy_para_rotulo_curto).fillna(tabela["opcao"])
tabela["label_pct"]   = tabela["perc"].map(lambda v: f"{v:.1f}%".replace(".", ","))
tabela["cor"] = tabela["opcao_curta"].map(CORES_FIXAS)

# ordenar pela % (decrescente) e “travar” a ordem no eixo
tabela = tabela.sort_values("perc", ascending=True)  # ascending=True pq vamos dar coord_flip
tabela["opcao_curta"] = pd.Categorical(tabela["opcao_curta"], categories=tabela["opcao_curta"], ordered=True)

# ---- 2) gráfico (barras horizontais) ----
plot = (
    ggplot(tabela, aes(x="opcao_curta", y="perc", fill="opcao_curta"))
    + geom_col(width=0.65)
    + geom_text(aes(label="label_pct"), nudge_y=1.2, size=11, ha="left")
    + coord_flip()
    + scale_fill_manual(values=list(tabela.drop_duplicates("opcao_curta")["cor"]))
    + labs(
        title="Riscos na agricultura irrigada que merecem atenção",
        x="",
        y="Percentual dos respondentes (%)",
    )
    + scale_y_continuous(expand=(0.01, 0), limits=(0, tabela["perc"].max()*1.15))
    + theme(
        figure_size=(10, 8),
        panel_grid_major_y=element_blank(),
        axis_text_y=element_text(size=13),
        axis_text_x=element_text(size=13),
        plot_title=element_text(size=12, weight="bold"),
        plot_caption=element_text(size=9),
        legend_title=element_blank(),
        legend_position="none"
    )
)
plot.show()

# ---- 3) “Legenda” para o slide: curto x descrição completa ----
legenda = (
    tabela[["opcao", "opcao_curta"]]
    .assign(descricao=tabela["opcao"].map(rotulo_original))
    .rename(columns={"opcao_curta": "rótulo_curto", "descricao": "descrição"})
    .drop_duplicates()
)
# Você pode exibir 'legenda' como uma tabela no slide.
```

## Riscos na agricultura irrigada que merecem atenção imediata Perfil Produtores

```{python}
#import pandas as pd
# guarda a base completa apenas uma vez
if "DF_ALL" not in globals():
    DF_ALL = df.copy()

# --- FILTRO OPCIONAL: manter só respondentes "Produtor Rural" ---
FILTRO_PRODUTOR = True  # mude para False para voltar à base completa

COL_RESP = "perfil"           # <<< ajuste para o nome da sua coluna
ROTULOS_PRODUTOR = ["Produtor Rural", "Produtor"]  # rótulos aceitos (ajuste se precisar)

if FILTRO_PRODUTOR:
    mask_prod = (
        df[COL_RESP]
        .astype("string")
        .str.normalize("NFKD")            # robusto a acentos
        .str.encode("ascii", "ignore").str.decode("ascii")
        .str.contains("|".join(ROTULOS_PRODUTOR), case=False, na=False)
    )
    df = DF_ALL.loc[mask_prod].copy()         # <<<<< a partir daqui, seu código segue igual
    # print(f"Filtrados {mask_prod.sum()} produtores de {len(mask_prod)} respostas.")

valid_opts = [
    "A escassez, a variabilidade hídrica e os eventos climáticos extremos representam desafios para a produção agrícola",
    "O uso ineficiente da água, que pode proporcionar a degradação ambiental e aumentar a escassez de recursos hídricos",
    "A ausência de sensores confiáveis e de sistemas inteligentes de irrigação que  limitam a eficiência no uso da água e a competitividade do produtor",
    "A redução da disponibilidade de mão-de-obra para trabalhos em atividades operacionais de campo",
    "As perdas pós-colheita e a baixa resistência das frutas ao transporte a longas distâncias comprometem a competitividade",
    "A vulnerabilidade a pragas, doenças, estresses bióticos/abióticos e a falta de automação na colheita e avaliação de qualidade são entraves à produção",
]

def norm(s: str) -> str:
    s = "".join(ch for ch in unicodedata.normalize("NFKD", str(s)) if not unicodedata.combining(ch))
    s = s.casefold().strip()
    s = re.sub(r"\s+", " ", s)
    return s

valid_norm = {norm(v): v for v in valid_opts}

def split_riscos_with_commas(raw):
    out = [pd.NA, pd.NA, pd.NA, pd.NA]
    if pd.isna(raw) or not str(raw).strip():
        return pd.Series(out, index=["riscos_1","riscos_2","riscos_3","riscos_4"])

    # 1) normalizar separadores: transforma ; e quebras de linha em vírgula
    txt = str(raw).replace(";", ",")
    txt = re.sub(r"[\r\n]+", ",", txt)

    # 2) split por vírgula e limpeza de bullets/hífens
    parts = [re.sub(r"^[\-\•]\s*", "", p.strip()) for p in txt.split(",")]
    parts = [p for p in parts if p]  # remove vazios

    # 3) “parser por blocos” até bater exatamente numa opção válida
    rec, unk, vistos = [], [], set()
    i, n = 0, len(parts)
    while i < n:
        matched = False
        for j in range(i, n):
            candidate = ", ".join(parts[i:j+1]).strip()
            key = norm(candidate)
            if key in valid_norm:
                lab = valid_norm[key]
                if lab not in vistos:
                    rec.append(lab); vistos.add(lab)
                i = j + 1
                matched = True
                break
        if not matched:
            unk.append(parts[i])
            i += 1

    # 4) preencher 1–3 com válidas (na ordem)
    for k in range(min(3, len(rec))):
        out[k] = rec[k]

    # 5) riscos_4 = desconhecidas (se houver) SENÃO válidas extras (4ª+)
    if unk:
        out[3] = " | ".join(dict.fromkeys(unk))
    elif len(rec) > 3:
        out[3] = " | ".join(rec[3:])

    return pd.Series(out, index=["riscos_1","riscos_2","riscos_3","riscos_4"])

# aplicar
df[["riscos_1","riscos_2","riscos_3","riscos_4"]] = df["riscos"].apply(split_riscos_with_commas)

```

```{python}
#import re, unicodedata
#import pandas as pd
from collections import defaultdict

# --- mapeamento: rótulo completo -> nome da dummy (edite os nomes se preferir) ---
rotulo_para_dummy_riscos = {
    "A escassez, a variabilidade hídrica e os eventos climáticos extremos representam desafios para a produção agrícola": "risco_clima",
    "O uso ineficiente da água, que pode proporcionar a degradação ambiental e aumentar a escassez de recursos hídricos": "inefic_agua",
    "A ausência de sensores confiáveis e de sistemas inteligentes de irrigação que  limitam a eficiência no uso da água e a competitividade do produtor": "ausencia_sensores",
    "A redução da disponibilidade de mão-de-obra para trabalhos em atividades operacionais de campo": "reducao_maodeobra",
    "As perdas pós-colheita e a baixa resistência das frutas ao transporte a longas distâncias comprometem a competitividade": "resistencias_pos_colhe",
    "A vulnerabilidade a pragas, doenças, estresses bióticos/abióticos e a falta de automação na colheita e avaliação de qualidade são entraves à produção": "vulnerab_pragas",
    "Resistência de pragas e doenças aos defensivos.": "vulnerab_pragas",
}

# normalizador (tira acento/caixa e compacta espaços)
def norm(s: str) -> str:
    s = "".join(ch for ch in unicodedata.normalize("NFKD", str(s)) if not unicodedata.combining(ch))
    s = s.casefold()
    s = re.sub(r"\s+", " ", s).strip()
    return s

# versões normalizadas das chaves
normkey_to_dummy_riscos = {norm(k): v for k, v in rotulo_para_dummy_riscos.items()}

# helper: pega as seleções da linha (somente riscos_1.._3; ignoramos riscos_4 pois é NA)
def coletar_riscos(row):
    itens = []
    for c in ["riscos_1","riscos_2","riscos_3","riscos_4"]:
        v = row.get(c, pd.NA)
        if pd.notna(v) and str(v).strip():
            itens.append(str(v))
    return [norm(x) for x in itens]

# cria as 7 dummies (0/1)
all_norm = df.apply(coletar_riscos, axis=1)

# --- AGRUPA keys por dummy, para poder fazer OR (any) corretamente ---
keys_by_dummy = defaultdict(list)
for nk, dummy in normkey_to_dummy_riscos.items():
    keys_by_dummy[dummy].append(nk)

# cria as dummies (0/1) — OR entre todas as chaves daquele dummy
for dummy, keys in keys_by_dummy.items():
    df[dummy] = all_norm.apply(lambda lst: int(any(k in lst for k in keys)))

# lista final de dummies criadas
dummy_riscos = list(keys_by_dummy.keys())
#print("Criadas:", dummy_riscos)
#print("Somas (quantos marcaram cada risco):")
#print(df[dummy_riscos].sum().sort_values(ascending=False))
```

```{python}
# série com as proporções (%)
r = (df[dummy_riscos].mean() * 100).round(1).sort_values(ascending=False)

# vira DataFrame com 2 colunas (opcao, perc)
tabela = r.rename_axis("opcao").reset_index(name="perc")
tabela
```

```{python}
#import pandas as pd
#from plotnine import *

# ---- 0) mapeamentos ----
dummy_para_rotulo_curto = {
    "risco_clima": "Clima & extremos",
    "inefic_agua": "Uso ineficiente da água",
    "ausencia_sensores": "Sem sensores/irrig. inteligente",
    "reducao_maodeobra": "Menor mão de obra disponível",
    "resistencias_pos_colhe": "Perdas pós-colheita",
    "vulnerab_pragas": "Pragas/doenças & automação",
}

# 1) Paleta fixa (10 cores) — troque pelos seus hex se já tiver um padrão

CORES_FIXAS = {
    "Clima & extremos": "#9BD34E",
    "Sem sensores/irrig. inteligente": "#F4E24A",
    "Menor mão de obra disponível": '#6d1575',
    "Pragas/doenças & automação": '#595f8f',
    "Uso Ineficiente da Água": '#178496',
    "Perdas pós-colheita": '#076140',
}

# rótulo curto e rótulo de texto com vírgula
tabela = tabela.copy()
tabela["opcao_curta"] = tabela["opcao"].map(dummy_para_rotulo_curto).fillna(tabela["opcao"])
tabela["label_pct"]   = tabela["perc"].map(lambda v: f"{v:.1f}%".replace(".", ","))
tabela["cor"] = tabela["opcao_curta"].map(CORES_FIXAS)

# ordenar pela % (decrescente) e “travar” a ordem no eixo
tabela = tabela.sort_values("perc", ascending=True)  # ascending=True pq vamos dar coord_flip
tabela["opcao_curta"] = pd.Categorical(tabela["opcao_curta"], categories=tabela["opcao_curta"], ordered=True)

# ---- 2) gráfico (barras horizontais) ----
plot = (
    ggplot(tabela, aes(x="opcao_curta", y="perc", fill="opcao_curta"))
    + geom_col(width=0.65)
    + geom_text(aes(label="label_pct"), nudge_y=1.2, size=11, ha="left")
    + coord_flip()
    + scale_fill_manual(values=list(tabela.drop_duplicates("opcao_curta")["cor"]))
    + labs(
        title="Riscos na agricultura irrigada que merecem atenção",
        x="",
        y="Percentual dos respondentes (%)",
    )
    + scale_y_continuous(expand=(0.01, 0), limits=(0, tabela["perc"].max()*1.15))
    + theme(
        figure_size=(10, 8),
        panel_grid_major_y=element_blank(),
        axis_text_y=element_text(size=13),
        axis_text_x=element_text(size=13),
        plot_title=element_text(size=12, weight="bold"),
        plot_caption=element_text(size=9),
        legend_title=element_blank(),
        legend_position="none"
    )
)
plot.show()

# ---- 3) “Legenda” para o slide: curto x descrição completa ----
legenda = (
    tabela[["opcao", "opcao_curta"]]
    .assign(descricao=tabela["opcao"].map(rotulo_original))
    .rename(columns={"opcao_curta": "rótulo_curto", "descricao": "descrição"})
    .drop_duplicates()
)
# Você pode exibir 'legenda' como uma tabela no slide.
df = DF_ALL.copy()
```

## Grau de importância que atribui para os temas abaixo relacionados

```{python}
#import re, unicodedata
#import pandas as pd

# 1) suas colunas Likert
cols = [
'importancia_melhoramento','importancia_manejo_agua','importancia_manejo_doencas','importancia_manejo_pragas','importancia_sistemas_prod','importancia_monit_gases','importancia_ferramentas_biotec','importancia_tecno_alimen','importancia_poscolheita','importancia_mercado',
]

# 2) normalizador (remove acentos, baixa caixa, comprime espaços)
def norm(s):
    if pd.isna(s): return s
    s = "".join(ch for ch in unicodedata.normalize("NFKD", str(s)) if not unicodedata.combining(ch))
    s = re.sub(r"\s+", " ", s.casefold().strip())
    return s

# 3) escolha de tratamento para "Não sei"
USE_NA_FOR_NAO_SEI = False  # True -> NA ; False -> 0

LIKERT_MAP = {
    "muito importante": 3,
    "moderadamente importante": 2,
    "pouco importante": 1,
    "nao sei": (pd.NA if USE_NA_FOR_NAO_SEI else 0),
}

# 4) aplicar em todas as colunas
unmapped_report = {}  # para checagem
for col in cols:
    # backup do rótulo original
    df[col + "_label"] = df[col]

    # mapeamento robusto
    df[col + "_code"] = (
        df[col].map(lambda x: LIKERT_MAP.get(norm(x), pd.NA))
               .astype("Int64")
    )

    # diagnosticar valores não mapeados (se houver)
    vals = df[col].dropna().unique().tolist()
    not_mapped = sorted({v for v in vals if LIKERT_MAP.get(norm(v), None) is None})
    if not_mapped:
        unmapped_report[col] = not_mapped

# 5) ver se sobrou algo não mapeado
#unmapped_report  # dict vazio = tudo ok
```

```{python}
#import pandas as pd

# suas colunas Likert
cols = [
'importancia_melhoramento','importancia_manejo_agua','importancia_manejo_doencas','importancia_manejo_pragas','importancia_sistemas_prod','importancia_monit_gases','importancia_ferramentas_biotec','importancia_tecno_alimen','importancia_poscolheita','importancia_mercado',
]

# ordem da escala (Não sei = 0 no seu mapeamento, mas aqui usamos os rótulos)
ordem = ["Muito importante", "Moderadamente importante", "Pouco importante", "Não sei"]

rows = []
for col in cols:
    s = df[col + "_label"].astype(pd.CategoricalDtype(categories=ordem, ordered=True))
    vc = s.value_counts(dropna=False, sort=False)  # já na ordem definida
    total = int(vc.sum())
    for cat in ordem:
        n = int(vc.get(cat, 0))
        perc = round(n / total * 100, 1) if total > 0 else pd.NA
        rows.append({"variavel": col, "categoria": cat, "perc": perc})

tabela_props = pd.DataFrame(rows)
#tabela_props
```

```{python}
tabela_wide = (
    tabela_props.pivot(index="variavel", columns="categoria", values="perc")
                .reindex(columns=ordem)   # garante ordem das colunas
                .reset_index()
)
tabela_wide
```

```{python}
# dados longos: cols = ["variavel","resposta","perc"]  # perc em 0–100
#from plotnine import *
#import pandas as pd

# mapeia o nome técnico -> rótulo curto (1 linha)
map_var_to_label = {
    "importancia_melhoramento":      "Melhoramento genético (frutas/oler.)",
    "importancia_manejo_agua":       "Manejo da água (irrig.)",
    "importancia_manejo_doencas":    "Manejo de doenças (irrig.)",
    "importancia_manejo_pragas":     "Manejo de pragas (irrig.)",
    "importancia_sistemas_prod":     "Sistemas de produção (frutas/oler.)",
    "importancia_monit_gases":       "Monit./mitigação de GEE",
    "importancia_ferramentas_biotec":"Biotecnologia aplicada",
    "importancia_tecno_alimen":      "Tecnologia de alimentos",
    "importancia_poscolheita":       "Pós-colheita (qualid./vida útil)",
    "importancia_mercado":           "Estudos de mercado/viabilidade",
}

ordem = ["Não sei","Pouco importante","Moderadamente importante","Muito importante"]
cores = {
    "Muito importante": "#076140",           # verde escuro
    "Moderadamente importante": "#2FA178",   # verde médio
    "Pouco importante": "#F4E24A",           # amarelo
    "Não sei": "#BAB0AC"                     # cinza
}

# 2) Aplica rótulos curtos (escolha com ou sem quebra de linha)
dfp = tabela_props.copy()
dfp["variavel"] = dfp["variavel"].map(map_var_to_label)
dfp["categoria"] = pd.Categorical(dfp["categoria"], categories=ordem, ordered=True)

# ordenar variáveis por % "Muito importante"
ord_var = (dfp.query('categoria=="Muito importante"')
              .sort_values("perc")["variavel"].tolist())
dfp["variavel"] = pd.Categorical(dfp["variavel"], categories=ord_var, ordered=True)

plot = (
  ggplot(dfp, aes(x="variavel", y="perc", fill="categoria"))
  + geom_col(width=0.75, position="fill")     # 100%
  + coord_flip()
  + scale_fill_manual(values={k:cores[k] for k in ordem})
  + scale_y_continuous(labels=lambda v: [f"{x*100:.0f}%" for x in v])
  + labs(x="", y="Distribuição (%)", fill="")
    + theme(
        figure_size=(10, 8),
        panel_grid_major_y=element_blank(),
        axis_text_y=element_text(size=13),
        axis_text_x=element_text(size=13),
        plot_title=element_text(size=12, weight="bold"),
        plot_caption=element_text(size=9),
        legend_title=element_blank(),
        legend_text=element_text(size=12),
        legend_position="bottom"
    )
)

plot.show()
```

## Grau de importância que atribui para os temas abaixo relacionados Perfil Produtores

```{python}
#import re, unicodedata
#import pandas as pd
# guarda a base completa apenas uma vez
if "DF_ALL" not in globals():
    DF_ALL = df.copy()

# --- FILTRO OPCIONAL: manter só respondentes "Produtor Rural" ---
FILTRO_PRODUTOR = True  # mude para False para voltar à base completa

COL_RESP = "perfil"           # <<< ajuste para o nome da sua coluna
ROTULOS_PRODUTOR = ["Produtor Rural", "Produtor"]  # rótulos aceitos (ajuste se precisar)

if FILTRO_PRODUTOR:
    mask_prod = (
        df[COL_RESP]
        .astype("string")
        .str.normalize("NFKD")            # robusto a acentos
        .str.encode("ascii", "ignore").str.decode("ascii")
        .str.contains("|".join(ROTULOS_PRODUTOR), case=False, na=False)
    )
    df = DF_ALL.loc[mask_prod].copy()         # <<<<< a partir daqui, seu código segue igual
    # print(f"Filtrados {mask_prod.sum()} produtores de {len(mask_prod)} respostas.")


# 1) suas colunas Likert
cols = [
'importancia_melhoramento','importancia_manejo_agua','importancia_manejo_doencas','importancia_manejo_pragas','importancia_sistemas_prod','importancia_monit_gases','importancia_ferramentas_biotec','importancia_tecno_alimen','importancia_poscolheita','importancia_mercado',
]

# 2) normalizador (remove acentos, baixa caixa, comprime espaços)
def norm(s):
    if pd.isna(s): return s
    s = "".join(ch for ch in unicodedata.normalize("NFKD", str(s)) if not unicodedata.combining(ch))
    s = re.sub(r"\s+", " ", s.casefold().strip())
    return s

# 3) escolha de tratamento para "Não sei"
USE_NA_FOR_NAO_SEI = False  # True -> NA ; False -> 0

LIKERT_MAP = {
    "muito importante": 3,
    "moderadamente importante": 2,
    "pouco importante": 1,
    "nao sei": (pd.NA if USE_NA_FOR_NAO_SEI else 0),
}

# 4) aplicar em todas as colunas
unmapped_report = {}  # para checagem
for col in cols:
    # backup do rótulo original
    df[col + "_label"] = df[col]

    # mapeamento robusto
    df[col + "_code"] = (
        df[col].map(lambda x: LIKERT_MAP.get(norm(x), pd.NA))
               .astype("Int64")
    )

    # diagnosticar valores não mapeados (se houver)
    vals = df[col].dropna().unique().tolist()
    not_mapped = sorted({v for v in vals if LIKERT_MAP.get(norm(v), None) is None})
    if not_mapped:
        unmapped_report[col] = not_mapped

# 5) ver se sobrou algo não mapeado
#unmapped_report  # dict vazio = tudo ok
```

```{python}
#import pandas as pd

# suas colunas Likert
cols = [
'importancia_melhoramento','importancia_manejo_agua','importancia_manejo_doencas','importancia_manejo_pragas','importancia_sistemas_prod','importancia_monit_gases','importancia_ferramentas_biotec','importancia_tecno_alimen','importancia_poscolheita','importancia_mercado',
]

# ordem da escala (Não sei = 0 no seu mapeamento, mas aqui usamos os rótulos)
ordem = ["Muito importante", "Moderadamente importante", "Pouco importante", "Não sei"]

rows = []
for col in cols:
    s = df[col + "_label"].astype(pd.CategoricalDtype(categories=ordem, ordered=True))
    vc = s.value_counts(dropna=False, sort=False)  # já na ordem definida
    total = int(vc.sum())
    for cat in ordem:
        n = int(vc.get(cat, 0))
        perc = round(n / total * 100, 1) if total > 0 else pd.NA
        rows.append({"variavel": col, "categoria": cat, "perc": perc})

tabela_props = pd.DataFrame(rows)
#tabela_props
```

```{python}
tabela_wide = (
    tabela_props.pivot(index="variavel", columns="categoria", values="perc")
                .reindex(columns=ordem)   # garante ordem das colunas
                .reset_index()
)
tabela_wide
```

```{python}
# dados longos: cols = ["variavel","resposta","perc"]  # perc em 0–100
#from plotnine import *
#import pandas as pd

# mapeia o nome técnico -> rótulo curto (1 linha)
map_var_to_label = {
    "importancia_melhoramento":      "Melhoramento genético (frutas/oler.)",
    "importancia_manejo_agua":       "Manejo da água (irrig.)",
    "importancia_manejo_doencas":    "Manejo de doenças (irrig.)",
    "importancia_manejo_pragas":     "Manejo de pragas (irrig.)",
    "importancia_sistemas_prod":     "Sistemas de produção (frutas/oler.)",
    "importancia_monit_gases":       "Monit./mitigação de GEE",
    "importancia_ferramentas_biotec":"Biotecnologia aplicada",
    "importancia_tecno_alimen":      "Tecnologia de alimentos",
    "importancia_poscolheita":       "Pós-colheita (qualid./vida útil)",
    "importancia_mercado":           "Estudos de mercado/viabilidade",
}

ordem = ["Não sei","Pouco importante","Moderadamente importante","Muito importante"]
cores = {
    "Muito importante": "#076140",           # verde escuro
    "Moderadamente importante": "#2FA178",   # verde médio
    "Pouco importante": "#F4E24A",           # amarelo
    "Não sei": "#BAB0AC"                     # cinza
}

# 2) Aplica rótulos curtos (escolha com ou sem quebra de linha)
dfp = tabela_props.copy()
dfp["variavel"] = dfp["variavel"].map(map_var_to_label)
dfp["categoria"] = pd.Categorical(dfp["categoria"], categories=ordem, ordered=True)

# ordenar variáveis por % "Muito importante"
ord_var = (dfp.query('categoria=="Muito importante"')
              .sort_values("perc")["variavel"].tolist())
dfp["variavel"] = pd.Categorical(dfp["variavel"], categories=ord_var, ordered=True)

plot = (
  ggplot(dfp, aes(x="variavel", y="perc", fill="categoria"))
  + geom_col(width=0.75, position="fill")     # 100%
  + coord_flip()
  + scale_fill_manual(values={k:cores[k] for k in ordem})
  + scale_y_continuous(labels=lambda v: [f"{x*100:.0f}%" for x in v])
  + labs(x="", y="Distribuição (%)", fill="")
    + theme(
        figure_size=(10, 8),
        panel_grid_major_y=element_blank(),
        axis_text_y=element_text(size=13),
        axis_text_x=element_text(size=13),
        plot_title=element_text(size=12, weight="bold"),
        plot_caption=element_text(size=9),
        legend_title=element_blank(),
        legend_text=element_text(size=12),
        legend_position="bottom"
    )
)

plot.show()

df = DF_ALL.copy()

```

## Grau de satisfação com atuação da Embrapa no desenvolvimento de tecnologias nas temáticas abaixo relacionadas

```{python}
#import re, unicodedata
#import pandas as pd

# 1) suas colunas Likert
cols = [
'satisfacao_melhoramento','satisfacao_manejo_agua','satisfacao_manejo_doencas','satisfacao_manejo_pragas',
    'satisfacao_sistemas_prod','satisfacao_monit_gases','satisfacao_ferramentas_biotec','satisfacao_tecno_alimen',
    'satisfacao_poscolheita','satisfacao_mercado',
]

# 2) normalizador (remove acentos, baixa caixa, comprime espaços)
def norm(s):
    if pd.isna(s): return s
    s = "".join(ch for ch in unicodedata.normalize("NFKD", str(s)) if not unicodedata.combining(ch))
    s = re.sub(r"\s+", " ", s.casefold().strip())
    return s

# 3) escolha de tratamento para "Não sei"
USE_NA_FOR_NAO_SEI = False  # True -> NA ; False -> 0

LIKERT_MAP = {
    "totalmente satisfeito": 5,
    "satisfeito": 4,
    "nem satisfeito nem insatisfeito": 3,
    "insatisfeito": 2,
    "totalmente insatisfeito": 1,
    "nao sei": (pd.NA if USE_NA_FOR_NAO_SEI else 0),
}

# 4) aplicar em todas as colunas
unmapped_report = {}  # para checagem
for col in cols:
    # backup do rótulo original
    df[col + "_label"] = df[col]

    # mapeamento robusto
    df[col + "_code"] = (
        df[col].map(lambda x: LIKERT_MAP.get(norm(x), pd.NA))
               .astype("Int64")
    )

    # diagnosticar valores não mapeados (se houver)
    vals = df[col].dropna().unique().tolist()
    not_mapped = sorted({v for v in vals if LIKERT_MAP.get(norm(v), None) is None})
    if not_mapped:
        unmapped_report[col] = not_mapped

# 5) ver se sobrou algo não mapeado
#unmapped_report  # dict vazio = tudo ok
```

```{python}
#import pandas as pd

# suas colunas Likert
cols = [
'satisfacao_melhoramento','satisfacao_manejo_agua','satisfacao_manejo_doencas','satisfacao_manejo_pragas',
    'satisfacao_sistemas_prod','satisfacao_monit_gases','satisfacao_ferramentas_biotec','satisfacao_tecno_alimen',
    'satisfacao_poscolheita','satisfacao_mercado',
]

# ordem da escala (Não sei = 0 no seu mapeamento, mas aqui usamos os rótulos)
ordem = ["Totalmente satisfeito", "Satisfeito", "Nem satisfeito nem insatisfeito", "Insatisfeito", "Totalmente insatisfeito", "Não sei"]

rows = []
for col in cols:
    s = df[col + "_label"].astype(pd.CategoricalDtype(categories=ordem, ordered=True))
    vc = s.value_counts(dropna=False, sort=False)  # já na ordem definida
    total = int(vc.sum())
    for cat in ordem:
        n = int(vc.get(cat, 0))
        perc = round(n / total * 100, 1) if total > 0 else pd.NA
        rows.append({"variavel": col, "categoria": cat, "n": n, "perc": perc})

tabela_props = pd.DataFrame(rows)
#tabela_props
```

```{python}
tabela_wide2 = (
    tabela_props.pivot(index="variavel", columns="categoria", values="perc")
                .reindex(columns=ordem)   # garante ordem das colunas
                .reset_index()
)
tabela_wide2
```

```{python}
# mapeia o nome técnico -> rótulo curto (1 linha)
map_var_to_label = {
    "satisfacao_melhoramento":      "Melhoramento genético (frutas/oler.)",
    "satisfacao_manejo_agua":       "Manejo da água (irrig.)",
    "satisfacao_manejo_doencas":    "Manejo de doenças (irrig.)",
    "satisfacao_manejo_pragas":     "Manejo de pragas (irrig.)",
    "satisfacao_sistemas_prod":     "Sistemas de produção (frutas/oler.)",
    "satisfacao_monit_gases":       "Monit./mitigação de GEE",
    "satisfacao_ferramentas_biotec":"Biotecnologia aplicada",
    "satisfacao_tecno_alimen":      "Tecnologia de alimentos",
    "satisfacao_poscolheita":       "Pós-colheita (qualid./vida útil)",
    "satisfacao_mercado":           "Estudos de mercado/viabilidade",
}

ordem = ["Não sei","Totalmente insatisfeito","Nem satisfeito nem insatisfeito","Satisfeito","Totalmente satisfeito"]
cores = {
    "Totalmente satisfeito": "#0e0663",           # azul escuro
    "Satisfeito": "#181078",   # azul médio
    "Nem satisfeito nem insatisfeito": "#281f91",           # azul
    "Totalmente insatisfeito": "#4237b3", #azul
    "Não sei": "#685dde"                     # cinza
}

# 1) Garantias de tipo
dfp = tabela_props.copy()
dfp["perc"] = pd.to_numeric(dfp["perc"], errors="coerce").fillna(0)

# 2) Rótulos curtos (já mapeiam 100%)
dfp["variavel"] = dfp["variavel"].map(map_var_to_label)

# 3) Categorias na ordem esperada (qualquer coisa fora vira "Não sei")
ordem = ["Não sei","Totalmente insatisfeito","Nem satisfeito nem insatisfeito","Satisfeito","Totalmente satisfeito"]
dfp.loc[~dfp["categoria"].isin(ordem), "categoria"] = "Não sei"
dfp["categoria"] = pd.Categorical(dfp["categoria"], categories=ordem, ordered=True)

# 4) Ordena e define como categórica
ord_var = (dfp.query('categoria=="Totalmente satisfeito"')
             .sort_values("perc")["variavel"].tolist())
if not ord_var:
    ord_var = sorted(dfp["variavel"].unique())
dfp["variavel"] = pd.Categorical(dfp["variavel"], categories=ord_var, ordered=True)

# 5) Cores + plot 100% empilhado
cores = {
    "Totalmente satisfeito": "#200663",
    "Satisfeito": "#336b96",
    "Nem satisfeito nem insatisfeito": "#59917d",
    "Totalmente insatisfeito": "#7febe3",
    "Não sei": "#076140"
}

plot = (
  ggplot(dfp, aes(x="variavel", y="perc", fill="categoria"))
  + geom_col(width=0.75, position="fill")
  + coord_flip()
  + scale_fill_manual(values={k: cores[k] for k in ordem})
  + scale_y_continuous(labels=lambda v: [f"{x*100:.0f}%" for x in v])
  + labs(x="", y="Distribuição (%)", fill="")
  + theme(
      figure_size=(10, 8),
      legend_title=element_blank(),
      legend_text=element_text(size=12),
      legend_position="bottom",
      panel_grid_major_y=element_blank(),
      axis_text_y=element_text(size=13),
      axis_text_x=element_text(size=13),
  )
)

plot.show()
```

## Grau de satisfação com atuação da Embrapa no desenvolvimento de tecnologias nas temáticas abaixo relacionadas Perfil Produtores

```{python}
#import re, unicodedata
#import pandas as pd

# guarda a base completa apenas uma vez
if "DF_ALL" not in globals():
    DF_ALL = df.copy()

# --- FILTRO OPCIONAL: manter só respondentes "Produtor Rural" ---
FILTRO_PRODUTOR = True  # mude para False para voltar à base completa

COL_RESP = "perfil"           # <<< ajuste para o nome da sua coluna
ROTULOS_PRODUTOR = ["Produtor Rural", "Produtor"]  # rótulos aceitos (ajuste se precisar)

if FILTRO_PRODUTOR:
    mask_prod = (
        df[COL_RESP]
        .astype("string")
        .str.normalize("NFKD")            # robusto a acentos
        .str.encode("ascii", "ignore").str.decode("ascii")
        .str.contains("|".join(ROTULOS_PRODUTOR), case=False, na=False)
    )
    df = DF_ALL.loc[mask_prod].copy()         # <<<<< a partir daqui, seu código segue igual
    # print(f"Filtrados {mask_prod.sum()} produtores de {len(mask_prod)} respostas.")

# 1) suas colunas Likert
cols = [
'satisfacao_melhoramento','satisfacao_manejo_agua','satisfacao_manejo_doencas','satisfacao_manejo_pragas',
    'satisfacao_sistemas_prod','satisfacao_monit_gases','satisfacao_ferramentas_biotec','satisfacao_tecno_alimen',
    'satisfacao_poscolheita','satisfacao_mercado',
]

# 2) normalizador (remove acentos, baixa caixa, comprime espaços)
def norm(s):
    if pd.isna(s): return s
    s = "".join(ch for ch in unicodedata.normalize("NFKD", str(s)) if not unicodedata.combining(ch))
    s = re.sub(r"\s+", " ", s.casefold().strip())
    return s

# 3) escolha de tratamento para "Não sei"
USE_NA_FOR_NAO_SEI = False  # True -> NA ; False -> 0

LIKERT_MAP = {
    "totalmente satisfeito": 5,
    "satisfeito": 4,
    "nem satisfeito nem insatisfeito": 3,
    "insatisfeito": 2,
    "totalmente insatisfeito": 1,
    "nao sei": (pd.NA if USE_NA_FOR_NAO_SEI else 0),
}

# 4) aplicar em todas as colunas
unmapped_report = {}  # para checagem
for col in cols:
    # backup do rótulo original
    df[col + "_label"] = df[col]

    # mapeamento robusto
    df[col + "_code"] = (
        df[col].map(lambda x: LIKERT_MAP.get(norm(x), pd.NA))
               .astype("Int64")
    )

    # diagnosticar valores não mapeados (se houver)
    vals = df[col].dropna().unique().tolist()
    not_mapped = sorted({v for v in vals if LIKERT_MAP.get(norm(v), None) is None})
    if not_mapped:
        unmapped_report[col] = not_mapped

# 5) ver se sobrou algo não mapeado
#unmapped_report  # dict vazio = tudo ok
```

```{python}
#import pandas as pd

# suas colunas Likert
cols = [
'satisfacao_melhoramento','satisfacao_manejo_agua','satisfacao_manejo_doencas','satisfacao_manejo_pragas',
    'satisfacao_sistemas_prod','satisfacao_monit_gases','satisfacao_ferramentas_biotec','satisfacao_tecno_alimen',
    'satisfacao_poscolheita','satisfacao_mercado',
]

# ordem da escala (Não sei = 0 no seu mapeamento, mas aqui usamos os rótulos)
ordem = ["Totalmente satisfeito", "Satisfeito", "Nem satisfeito nem insatisfeito", "Insatisfeito", "Totalmente insatisfeito", "Não sei"]

rows = []
for col in cols:
    s = df[col + "_label"].astype(pd.CategoricalDtype(categories=ordem, ordered=True))
    vc = s.value_counts(dropna=False, sort=False)  # já na ordem definida
    total = int(vc.sum())
    for cat in ordem:
        n = int(vc.get(cat, 0))
        perc = round(n / total * 100, 1) if total > 0 else pd.NA
        rows.append({"variavel": col, "categoria": cat, "n": n, "perc": perc})

tabela_props = pd.DataFrame(rows)
#tabela_props
```

```{python}
tabela_wide2 = (
    tabela_props.pivot(index="variavel", columns="categoria", values="perc")
                .reindex(columns=ordem)   # garante ordem das colunas
                .reset_index()
)
tabela_wide2
```

```{python}
# mapeia o nome técnico -> rótulo curto (1 linha)
map_var_to_label = {
    "satisfacao_melhoramento":      "Melhoramento genético (frutas/oler.)",
    "satisfacao_manejo_agua":       "Manejo da água (irrig.)",
    "satisfacao_manejo_doencas":    "Manejo de doenças (irrig.)",
    "satisfacao_manejo_pragas":     "Manejo de pragas (irrig.)",
    "satisfacao_sistemas_prod":     "Sistemas de produção (frutas/oler.)",
    "satisfacao_monit_gases":       "Monit./mitigação de GEE",
    "satisfacao_ferramentas_biotec":"Biotecnologia aplicada",
    "satisfacao_tecno_alimen":      "Tecnologia de alimentos",
    "satisfacao_poscolheita":       "Pós-colheita (qualid./vida útil)",
    "satisfacao_mercado":           "Estudos de mercado/viabilidade",
}

ordem = ["Não sei","Totalmente insatisfeito","Nem satisfeito nem insatisfeito","Satisfeito","Totalmente satisfeito"]
cores = {
    "Totalmente satisfeito": "#0e0663",           # azul escuro
    "Satisfeito": "#181078",   # azul médio
    "Nem satisfeito nem insatisfeito": "#281f91",           # azul
    "Totalmente insatisfeito": "#4237b3", #azul
    "Não sei": "#685dde"                     # cinza
}

# 1) Garantias de tipo
dfp = tabela_props.copy()
dfp["perc"] = pd.to_numeric(dfp["perc"], errors="coerce").fillna(0)

# 2) Rótulos curtos (já mapeiam 100%)
dfp["variavel"] = dfp["variavel"].map(map_var_to_label)

# 3) Categorias na ordem esperada (qualquer coisa fora vira "Não sei")
ordem = ["Não sei","Totalmente insatisfeito","Nem satisfeito nem insatisfeito","Satisfeito","Totalmente satisfeito"]
dfp.loc[~dfp["categoria"].isin(ordem), "categoria"] = "Não sei"
dfp["categoria"] = pd.Categorical(dfp["categoria"], categories=ordem, ordered=True)

# 4) Ordena e define como categórica
ord_var = (dfp.query('categoria=="Totalmente satisfeito"')
             .sort_values("perc")["variavel"].tolist())
if not ord_var:
    ord_var = sorted(dfp["variavel"].unique())
dfp["variavel"] = pd.Categorical(dfp["variavel"], categories=ord_var, ordered=True)

# 5) Cores + plot 100% empilhado
cores = {
    "Totalmente satisfeito": "#200663",
    "Satisfeito": "#336b96",
    "Nem satisfeito nem insatisfeito": "#59917d",
    "Totalmente insatisfeito": "#7febe3",
    "Não sei": "#076140"
}

plot = (
  ggplot(dfp, aes(x="variavel", y="perc", fill="categoria"))
  + geom_col(width=0.75, position="fill")
  + coord_flip()
  + scale_fill_manual(values={k: cores[k] for k in ordem})
  + scale_y_continuous(labels=lambda v: [f"{x*100:.0f}%" for x in v])
  + labs(x="", y="Distribuição (%)", fill="")
  + theme(
      figure_size=(10, 8),
      legend_title=element_blank(),
      legend_text=element_text(size=12),
      legend_position="bottom",
      panel_grid_major_y=element_blank(),
      axis_text_y=element_text(size=13),
      axis_text_x=element_text(size=13),
  )
)

plot.show()

df = DF_ALL.copy()

```

```{python}
#| eval: true
#| echo: false
#| message: false
#| warning: false

# ============================================
# AGRICULTURA IRRIGADA — MATRIZ IMPORTÂNCIA x SATISFAÇÃO
# thresholds: Importância >= 80%; Satisfação >= 50%
# ============================================

import pandas as pd
import unicodedata

AREA = "Agricultura Irrigada"
thr_importancia = 80.0
thr_satisfacao  = 50.0

# --- 1) Funções utilitárias ---
def _norm(s: str) -> str:
    """lower + remove acento + tira espaços extras; lida com NaN."""
    s = str(s).strip().lower()
    s = unicodedata.normalize("NFKD", s).encode("ascii","ignore").decode("utf-8")
    return s

def _pct(series, keys):
    """percentual (0-100) somado de chaves canonicalizadas."""
    vals = series.dropna().map(_norm)
    vc = (vals.value_counts(normalize=True) * 100)
    return round(float(sum(vc.get(k, 0.0) for k in keys)), 1)

# --- 2) Canonicalização das opções ---
# Importância (cubra variações como "Muito importante", "muito imp.", etc.)
IMP_MUITO      = {"muito importante", "muito", "mto importante"}
IMP_MODERADO   = {"moderadamente importante", "moderado", "moderadamente"}
IMP_POUCO      = {"pouco importante", "pouco"}
IMP_NSEI       = {"nao sei", "nao sei.", "não sei", "ns"}

# Satisfação (com e sem acento/maiúsculas; ordem 1..5 + "nao sei")
SAT_TOT_INSAT  = {"totalmente insatisfeito", "1", "ti"}
SAT_INSAT      = {"insatisfeito", "2", "i"}
SAT_MEIO       = {"nem satisfeito nem insatisfeito", "3", "neutro", "indiferente"}
SAT_SAT        = {"satisfeito", "4", "s"}
SAT_TOT_SAT    = {"totalmente satisfeito", "5", "ts"}
SAT_NSEI       = {"nao sei", "nao sei.", "não sei", "ns"}

# --- 3) Mapeamento de rótulos bonitos (ajuste se quiser) ---
label_map = {
    "ferramentas_biotec": "Ferramentas biotecnológicas",
    "manejo_agua":        "Manejo de água",
    "manejo_doencas":     "Manejo de doenças",
    "manejo_pragas":      "Manejo de pragas",
    "melhoramento":       "Melhoramento",
    "mercado":            "Inteligência/mercado",
    "monit_gases":        "Monitoramento de gases",
    "poscolheita":        "Pós-colheita",
    "sistemas_prod":      "Sistemas de produção",
    "tecno_alimen":       "Tecnologias de alimentos",
}

# --- 4) Descobrir pares importancia_/satisfacao_ nesta base ---
cols_imp  = [c for c in df.columns if c.startswith("importancia_")]
cols_sat  = [c for c in df.columns if c.startswith("satisfacao_")]

def short(k): 
    return (k.replace("importancia_","").replace("satisfacao_",""))

keys = sorted(set(short(c) for c in cols_imp) & set(short(c) for c in cols_sat))

# --- 5) Construir tabelas por tema ---
imp_rows, sat_rows = [], []

for k in keys:
    c_imp, c_sat = f"importancia_{k}", f"satisfacao_{k}"
    tema = label_map.get(k, k)

    # Importância
    pct_muito    = _pct(df[c_imp], IMP_MUITO)
    pct_mod      = _pct(df[c_imp], IMP_MODERADO)
    pct_pouco    = _pct(df[c_imp], IMP_POUCO)
    pct_imp_nsei = _pct(df[c_imp], IMP_NSEI)
    pct_alta     = round(pct_muito + pct_mod, 1)

    imp_rows.append({
        "Tema": tema,
        "% Muito importante": pct_muito,
        "% Moderadamente importante": pct_mod,
        "% Pouco importante": pct_pouco,
        "% Não sei (importância)": pct_imp_nsei,
        "alta_importância_muito+moderado(%)": pct_alta
    })

    # Satisfação
    pct_ts   = _pct(df[c_sat], SAT_TOT_SAT)
    pct_s    = _pct(df[c_sat], SAT_SAT)
    pct_mid  = _pct(df[c_sat], SAT_MEIO)
    pct_i    = _pct(df[c_sat], SAT_INSAT)
    pct_ti   = _pct(df[c_sat], SAT_TOT_INSAT)
    pct_sat_nsei = _pct(df[c_sat], SAT_NSEI)

    sat_rows.append({
        "Tema": tema,
        "% Totalmente satisfeito": pct_ts,
        "% Satisfeito": pct_s,
        "% Nem satisfeito nem insatisfeito": pct_mid,
        "% Insatisfeito": pct_i,
        "% Totalmente insatisfeito": pct_ti,
        "% Não sei (satisfação)": pct_sat_nsei,
        "satisfeitos_(4ou5)(%)": round(pct_s + pct_ts, 1),
        "nao_satisfeitos_(1a3)(%)": round(pct_ti + pct_i + pct_mid, 1),
    })

imp_tbl = pd.DataFrame(imp_rows).sort_values("Tema")
sat_tbl = pd.DataFrame(sat_rows).sort_values("Tema")

# --- 6) Diagnóstico (join + quadrantes) ---
diagnostico_irrig = (
    imp_tbl.merge(
        sat_tbl,
        on="Tema", how="inner"
    )
)

diagnostico_irrig["Importância alta?"] = diagnostico_irrig["alta_importância_muito+moderado(%)"] >= thr_importancia
diagnostico_irrig["Satisfação alta?"]  = diagnostico_irrig["satisfeitos_(4ou5)(%)"] >= thr_satisfacao

def quad(row):
    imp, sat = row["Importância alta?"], row["Satisfação alta?"]
    if imp and sat:     return "FORÇA INSTITUCIONAL"
    if imp and not sat: return "PRIORIDADE ESTRATÉGICA"
    if not imp and sat: return "ADEQUADO"
    return "BAIXA PRIORIDADE"

diagnostico_irrig["Quadrante"] = diagnostico_irrig.apply(quad, axis=1)

# --- 7) Saídas para relatório/slide ---
print(f"=== {AREA} — TABELA DE IMPORTÂNCIA POR TEMA ===")
print(imp_tbl[[
    "Tema","% Muito importante","% Moderadamente importante",
    "% Pouco importante","% Não sei (importância)",
    "alta_importância_muito+moderado(%)"
]].to_markdown(index=False))

print(f"\n=== {AREA} — TABELA DE SATISFAÇÃO POR TEMA ===")
print(sat_tbl[[
    "Tema","% Totalmente satisfeito","% Satisfeito",
    "% Nem satisfeito nem insatisfeito","% Insatisfeito",
    "% Totalmente insatisfeito","% Não sei (satisfação)",
    "satisfeitos_(4ou5)(%)"
]].to_markdown(index=False))

cols_show = ["Tema","alta_importância_muito+moderado(%)","satisfeitos_(4ou5)(%)",
             "Importância alta?","Satisfação alta?","Quadrante"]
print(f"\n=== {AREA} — DIAGNÓSTICO (IMPORTÂNCIA x SATISFAÇÃO) ===")
print(diagnostico_irrig[cols_show].sort_values(["Quadrante","Tema"]).to_markdown(index=False))

resumo_quad_irrig = (
    diagnostico_irrig.groupby("Quadrante")
    .agg(Temas=("Tema", lambda s: ", ".join(sorted(s))))
    .reset_index()
)
print("\n=== QUADRANTES E TEMAS — AGRICULTURA IRRIGADA ===")
print(resumo_quad_irrig.to_markdown(index=False))
```

```{python}
# =======================
# TABELA FINAL — IRRIGADA
# =======================

# 1) ordenação desejada dos quadrantes
ordem_quadrantes = {
    "FORÇA INSTITUCIONAL": 1,
    "PRIORIDADE ESTRATÉGICA": 2,
    "ADEQUADO": 3,
    "BAIXA PRIORIDADE": 4,
}

# 2) dataframe enxuto com as colunas na ordem do relatório
tabela_irrig = (
    diagnostico_irrig.loc[:, [
        "Tema",
        "alta_importância_muito+moderado(%)",
        "satisfeitos_(4ou5)(%)",
        "Importância alta?",
        "Satisfação alta?",
        "Quadrante"
    ]]
    .assign(_ord = lambda d: d["Quadrante"].map(ordem_quadrantes).fillna(99))
    .sort_values(["_ord","Tema"], kind="stable")
    .drop(columns="_ord")
    .rename(columns={
        "alta_importância_muito+moderado(%)": "% Importância (Muito + Moderado)",
        "satisfeitos_(4ou5)(%)": "% Satisfeitos (4 + 5)"
    })
)

# 3) opção A: imprimir em markdown (ponto decimal)
print("=== Tabela — Agricultura Irrigada (ponto decimal) ===")
print(tabela_irrig.to_markdown(index=False))

# 4) opção B: imprimir em markdown com VÍRGULA decimal (para colar no relatório)
def _fmt_com_virgula(x):
    if isinstance(x, (int, float)):
        return f"{x:.1f}".replace(".", ",")
    return x

tabela_irrig_pt = tabela_irrig.copy()
for col in ["% Importância (Muito + Moderado)", "% Satisfeitos (4 + 5)"]:
    tabela_irrig_pt[col] = tabela_irrig_pt[col].map(_fmt_com_virgula)

print("\n=== Tabela — Agricultura Irrigada (vírgula decimal) ===")
print(tabela_irrig_pt.to_markdown(index=False))

# 5) (opcional) salvar CSV para anexar no relatório
#tabela_irrig.to_csv("tabela_irrigada.csv", index=False, encoding="utf-8")
```


# Contribuição da Embrapa Semiárido para o desenvolvimento agropecuário do país

```{python}
ordem = ["Muito relevante","Razoavelmente relevante","Pouco relevante","Não é relevante","Não conheço o suficiente para opinar"]
map_q = {k:i for i,k in enumerate(ordem)}          # Muito Ruim=0 … Excelente=4
df["contribuicao_sociedade_code"] = df["contribuicao_sociedade"].map(map_q).astype("Int64")
```

```{python}
(df["contribuicao_sociedade"].value_counts(normalize=True) * 100).round(1).astype(str) + "%"
```

```{python}
# 1) preparar dados (percentuais por qualidade_pesq, ordenados)
dist = (
    df['contribuicao_sociedade'].fillna('Sem Resposta')                      # evita NaN aparecer na legenda
      .value_counts(dropna=False)
      .rename_axis('contribuicao_sociedade').reset_index(name='n')
)
dist['pct'] = dist['n'] / dist['n'].sum() * 100
#dist = dist.sort_values('pct', ascending=False).reset_index(drop=True)

# manter ordem no eixo e na legenda
#dist['contribuicao_sociedade'] = pd.Categorical(dist['contribuicao_sociedade'], categories=dist['contribuicao_sociedade'], ordered=True)
# reindex para aparecerem todas as categorias (mesmo as ausentes) na ordem da escala
dist = (dist.set_index('contribuicao_sociedade')
            .reindex(ordem, fill_value=0)
            .reset_index())

# manter ordem no eixo e na legenda
dist['contribuicao_sociedade'] = pd.Categorical(dist['contribuicao_sociedade'], categories=ordem, ordered=True)
pad = max(1.0, dist['pct'].max() * 0.04)   # ~6% da barra mais alta ou 1.5, o maior
dist['label']  = dist['pct'].round(1).astype(str) + '%'
dist['y_text'] = dist['pct'] + pad
y_top = dist['y_text'].max() + pad          # garante folga no topo

plot = (
    ggplot(dist, aes(x='contribuicao_sociedade', y='pct', fill='contribuicao_sociedade'))
    + geom_col(width=0.75)
    + geom_text(aes(y='y_text', label='label'), va='bottom', size=13)
    + scale_y_continuous(
        limits=(0, y_top),                   # <<< evita cortar a 1ª etiqueta
        expand=(0, 0),
        labels=lambda v: [f'{x:.0f}%' for x in v]
    )
    + scale_x_discrete(expand=(0, 0)) 
    + labs(title='Contribuição para o Desenvolvimento', x='', y='%', fill='CONTRIBUIÇÃO PARA O PAÍS')
    + theme(
        figure_size=(10, 8),
        legend_position='none',
        legend_direction='horizontal',
        legend_title=element_text(size=13),
        legend_text=element_text(size=13),
        axis_text_y=element_text(size=13),
        axis_text_x=element_text(size=13, angle=45, ha='right')
    )
)

plot.show()
```

# Demandas

```{python}
#import re, unicodedata
#import pandas as pd

def strip_acc(s: str) -> str:
    return "".join(ch for ch in unicodedata.normalize("NFKD", s) if not unicodedata.combining(ch))

def norm_text(s: str) -> str:
    s = strip_acc(s).casefold()
    s = re.sub(r"\s+", " ", s).strip()
    return s

# crie uma cópia “limpa”
df["demandas_label"] = df["demandas"]  # backup do texto original
df["demandas_clean"] = (
    df["demandas"]
      .astype(str)
      .str.strip()
      .replace({"": pd.NA, "nan": pd.NA, "NaN": pd.NA, "Sem comentários": pd.NA, "sem comentarios": pd.NA})
)

# versão normalizada (sem acentos/minúscula) – útil pra buscas
df["demandas_norm"] = df["demandas_clean"].dropna().map(norm_text)

```

```{python}
# stopwords bem simples PT-BR (edite à vontade)
stops = {
    "de","da","do","das","dos","e","a","o","as","os","um","uma","para","por","com",
    "no","na","nos","nas","em","sobre","que","ao","à","às","ou","se","como","sobre",
    "mais","menos","muito","pouco"
}

# tokenização super simples (palavras com letras acentuadas e números)
def tokenize(s: str):
    return re.findall(r"[a-zA-ZÀ-ÿ0-9]+", s)

tokens = []
for txt in df["demandas_norm"].dropna():
    for t in tokenize(txt):
        t2 = t.lower()
        if t2 not in stops and len(t2) > 2:
            tokens.append(t2)

#pd.Series(tokens).value_counts().head(30)

```

```{python}
from collections import Counter

#bigrams = []
#for txt in df["demandas_norm"].dropna():
#    toks = [t for t in tokenize(txt) if t not in stops and len(t) > 2]
#    bigrams += list(zip(toks, toks[1:]))

#Counter(bigrams).most_common(20)

```

```{python}
def any_match(text, patterns):
    # text já normalizado; patterns devem ser strings simples
    return any(p in text for p in patterns)

#temas = {
#    "forragens":       ["forrag", "palma", "sorgo", "buffel"],
#    "caprinos_ovinos": ["caprin", "ovin"],
#    "caatinga":        ["caatinga", "restauracao", "conservacao"],
#    "irrigacao":       ["irrigacao", "eficiencia"],
#    "biossalina":      ["biossalin"],
#    "energia":         ["energia", "fotovoltaic", "solar", "eolica"],
#    "mecanizacao":     ["mecaniza", "maquina"],
#    "aguas_salobras":  ["aguas de poco", "salobr"],
#    "produtos_regionais": ["panc", "licuri", "umbu", "queijo artesan"],
#    "gestao":          ["gestao", "empreendimentos rurais", "tomada de decis"],
#}

#for nome, pats in temas.items():
#    df[nome] = df["demandas_norm"].fillna("").apply(lambda s: int(any_match(s, pats)))

#df[list(temas.keys())].sum().sort_values(ascending=False)
```

```{python}
tabela_demandas = (
    df.loc[df["demandas"].notna(), ["demandas"]]
      .rename(columns={"demandas": "demanda"})
      .reset_index()                # traz o índice original
      .rename(columns={"index": "linha"})
)
#tabela_demandas
#import pandas as pd

pd.set_option("display.max_colwidth", None)
tabela_demandas  # só avaliar a célula já mostra completo
```

# Comentários

```{python}
tabela_comentarios = (
    df.loc[df["comentarios"].notna(), ["comentarios"]]
      .rename(columns={"comentarios": "comentarios"})
      .reset_index()                # traz o índice original
      .rename(columns={"index": "linha"})
)
tabela_comentarios
```
